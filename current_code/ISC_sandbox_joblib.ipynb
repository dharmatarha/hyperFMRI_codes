{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/jeffreyknotts/Documents/Wheatley_Lab/')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as mplot\n",
    "from numpy.random import random_sample\n",
    "from math import pi\n",
    "from math import sqrt\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#input parameters\n",
    "dbicSubs = list(range(1,3)) #using 1 and 9 as inputs gives 1:8, which will function as 2:9 according to matlab indexing\n",
    "cbsSubs = list(range(1,3))\n",
    "winTRs = 41 #window size [TRs]\n",
    "stepSize = 41 #step size [TRs] \n",
    "maxT = 6 #max TR lag to include in linear models\n",
    "voxelCoords = list(range(0,1000)) #whole brain = 1:69880 -- should add step above this that gets ROI voxel coords\n",
    "fitPermuts = 1000 #0 = don't use permutation test for pair fits\n",
    "groupPermuts = 1000\n",
    "method = 1 #0=old scrambling method, 1=new method of scrambling all voxels at once\n",
    "local = 0 #for JD debugging locally -- will eventually remove\n",
    "parallel = 1 #use joblib on pairwise for loop\n",
    "numJobs = 4 #number of cores for joblib to use\n",
    "totalTRs = 615 #kind of hacky but predefining the total number of TRs that will be in each timeseries\n",
    "voxParallel = 0 #use joblib on voxelwise for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#load pair and run data\n",
    "pairsAndRuns = pd.read_csv(r'/afs/.dbic.dartmouth.edu/usr/wheatley/jd/hyperscanning_pair_and_run_lookup.csv')\n",
    "print(pairsAndRuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mark starting time \n",
    "startTime = time.time()\n",
    "\n",
    "#get numbers of pairs\n",
    "realPairN = len(list(set(dbicSubs) & set(cbsSubs)))\n",
    "pseudoPairN = len(dbicSubs)*len(cbsSubs) - realPairN\n",
    "totalPairN = realPairN + pseudoPairN\n",
    "\n",
    "#define some rolling window parameters based on inputs above\n",
    "totTRs = 615.0; #total # of TRs in each time series -- needs to be floating point for the steps below to work properly\n",
    "numSteps = int(math.ceil((totTRs - winTRs + 1) / stepSize)) #total number of steps based on winTR and stepSize\n",
    "lastTr = winTRs + (numSteps - 1) * stepSize #last TR this approach will analyze\n",
    "TRsLeftOut = totTRs - lastTr #number of TRs that will be left out by the current approach\n",
    "if TRsLeftOut > 0: #if any TRs will end up getting left out based on window and step sizes...\n",
    "    print('The last ' + str(TRsLeftOut) + ' TRs will be left out due to the window and step size!')\n",
    "    \n",
    "#preallocate fit arrays\n",
    "#arrays are structured as follows (using realFits as an example):\n",
    "#realFits[0] = independent condition\n",
    "#realFits[1] = joint condition\n",
    "#realFits[0][0] = beta coefficients [pairs x betas x voxels x windows]\n",
    "#realFits[0][1] = R^2 [pairs x voxels x windows]\n",
    "#realFits[0][2] = F [pairs x voxels x windows]\n",
    "#realFits[0][3] = pF (p-value for F-test) [pairs x voxels x windows]\n",
    "#realFits[0][4] = pP_Rsq (p-value for R^2 from permutation test) [pairs x voxels x windows]\n",
    "rRows = realPairN * 2; #number of rows to preallocate for real fit arrays\n",
    "pRows = pseudoPairN * 2; #number of rows to preallocate for pseudo fit arrays\n",
    "realFits = [[]]*2 #begin preallocation\n",
    "pseudoFits = [[]]*2 #begin preallocation\n",
    "for COND in list(range(0,len(realFits))): #for each condition (independent and joint)...\n",
    "    realFits[COND] = [[]]*5\n",
    "    pseudoFits[COND] = [[]]*5\n",
    "    for MEAS in list(range(0,5)): #for each model fit measure...\n",
    "        if MEAS == 0:\n",
    "            realFits[COND][MEAS] = np.empty([rRows,2*maxT+1, len(voxelCoords), numSteps])\n",
    "            pseudoFits[COND][MEAS] = np.empty([pRows,2*maxT+1, len(voxelCoords), numSteps])\n",
    "        else:\n",
    "            realFits[COND][MEAS] = np.empty([rRows,len(voxelCoords), numSteps])\n",
    "            pseudoFits[COND][MEAS] = np.empty([pRows,len(voxelCoords), numSteps])\n",
    "            \n",
    "#preallocate map of which pairs correspond to which rows for the fit data\n",
    "pairMap_header = ['dbic','cbs','cbsSpeaker']\n",
    "pairMap = [[]]*2\n",
    "pairMap[0] = np.empty([pRows,len(pairMap_header)]) #pair mappings for realFits\n",
    "pairMap[1] = np.empty([rRows,len(pairMap_header)]) #pair mappings for pseudoFits\n",
    "\n",
    "#create empty dummy array for voxelwise joblib functions\n",
    "modArray = realFits[0]\n",
    "\n",
    "#preallocate timing log\n",
    "timeLog_header = ['dbic','cbs','duration']\n",
    "timeLog = np.empty([totalPairN,len(timeLog_header)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def naiveColumnCorr(a, b): \n",
    "    \"\"\"\n",
    "    Naive, slow, \"baseline\" function correlating corresponding columns of two matrices.\n",
    "    Uses a for loop across columns.\n",
    "    \"\"\"\n",
    "    c = np.zeros((a.shape[1]))\n",
    "    for i in range(a.shape[1]):\n",
    "        c[i] = np.corrcoef(a[:, i], b[:, i])[0, 1]\n",
    "\n",
    "    return c\n",
    "\n",
    "\n",
    "def fastColumnCorr(a, b):\n",
    "    \"\"\"\n",
    "    Fast function for correlating corresponding columns of two matrices.\n",
    "    Uses numpy.einsum to avoid loops and do computations directly on matrices.\n",
    "    About ~ 10 times faster than the naive approach in 'naiveColumnCorr'.\n",
    "    Inputs are 2D numpy arrays with the same shape, both sized samples X vars.\n",
    "    NOTES:\n",
    "    Could be further optimized using numpy.einsum_path for contraction order before first use,\n",
    "    then simply calling einsum with that order subsequently. However, it only seems to give a\n",
    "    few percents at best.\n",
    "    contr_order = np.einsum_path(\"ij,ij->j\", aa, bb, optimize='optimal')\n",
    "    cov = np.einsum(\"ij,ij->j\", aa, bb, optimize=contr_order[1])\n",
    "    \"\"\"\n",
    "    # extract the means from each var, in both matrices\n",
    "    aa = a - (np.sum(a, 0) / a.shape[0]) # compute a - mean(a)\n",
    "    bb = b - (np.sum(b, 0) / b.shape[0]) # compute b - mean(b)\n",
    "\n",
    "    # multiply and sum across rows, that is, get dot products of column pairs\n",
    "    cov = np.einsum(\"ij,ij->j\", aa, bb)\n",
    "\n",
    "    # for normalization we need the variances, separately for each var\n",
    "    var_a = np.sum(aa ** 2, 0)\n",
    "    var_b = np.sum(bb ** 2, 0)\n",
    "\n",
    "    return cov / np.sqrt(var_a*var_b)\n",
    "\n",
    "\n",
    "\n",
    "def phase_scrambling(data_matrix, fft_axis=0):\n",
    "    \"\"\"\n",
    "    FOR REAL DATA ONLY, NOT COMPLEX!\n",
    "    Phase-scrambling function for matrices. Preserves the original covariance structure.\n",
    "    After FFT, we add a random phase vector to the FFT components of all time series / vars and do inverse FFT,\n",
    "    as described in Prichard and Theiler (1994, Generating surrogate data for time series with several\n",
    "    simultaneously measured variables. Physical review letters, 73(7), 951).\n",
    "    The returned phase-scrambled data has the same power spectrum as the original but is linearly independent\n",
    "    (zero expected correlation). Covariance structure is preserved, meaning that linear dependencies\n",
    "    across time series is the same in the phase-scrambled data as in the original.\n",
    "    Inputs:\n",
    "    data_matrix:        2D numpy array of reals. Time series (Vars) X samples by default,\n",
    "                        set fft_axis if samples X time series.\n",
    "    fft_axis:           Axis along which FFT / iFFT is calculated. Defaults to 0,\n",
    "                        meaning that FFT is calculated across rows (= each column is a separate time series / var)\n",
    "    Outputs:\n",
    "    data_scrambled:     2D numpy array of reals, contains the phase-scrambled data.\n",
    "                        Same size and dimensions as input \"data_matrix\".\n",
    "                        Returns 0 if input checks failed.\n",
    "    TODO:\n",
    "    - look into implementation with FFTW, which is supposedly faster with repetitive usage (our use case)\n",
    "    \"\"\"\n",
    "\n",
    "    # input checks\n",
    "    if not isinstance(data_matrix, np.ndarray) or len(data_matrix.shape) != 2 or np.iscomplex(data_matrix).any():\n",
    "        print('Input arg \"data_matrix\" should be a 2D numpy array of reals!')\n",
    "        return 0\n",
    "    if fft_axis not in [0, 1]:\n",
    "        print('Input arg \"fft_axis\" should be 0 or 1!')\n",
    "        return 0\n",
    "\n",
    "    # if fft_axis != 0, transpose the data\n",
    "    transposeFlag = False\n",
    "    if fft_axis == 1:\n",
    "        data_matrix = np.transpose(data_matrix)\n",
    "        transposeFlag = True\n",
    "\n",
    "    # do forward FFT, use version for reals, treat data as if vars were in columns\n",
    "    data_fft = np.fft.rfft(data_matrix, axis=0)\n",
    "\n",
    "    # convert to polar coordinates (amplitude/magnitude + phase)\n",
    "    data_fft_amp = np.abs(data_fft)\n",
    "    data_fft_angle = np.angle(data_fft)\n",
    "\n",
    "    # get random phase vector  (values between 0 - 2pi) for all FFT components that are not real by definition\n",
    "    rng = default_rng()  # new recommended method for random values\n",
    "    if data_matrix.shape[0] % 2 == 0:  # if even, first and last components are real\n",
    "        rand_phases = np.hstack(([0] ,(rng.random((data_fft.shape[0]-2)) * 2 * pi), [0]))\n",
    "    else:  # otherwise only the first component is real\n",
    "        rand_phases = np.hstack(([0], (rng.random((data_fft.shape[0] - 1)) * 2 * pi)))\n",
    "\n",
    "    # add random phases to the angles of FFT components of all time series / vars,\n",
    "    # addition is with broadcasting (newaxis is needed for broadcasting)\n",
    "    data_fft_angle_rand = data_fft_angle + rand_phases[:, np.newaxis]\n",
    "\n",
    "    # transform back from polar to cartesian, using the randomized phases but the original magnitude / amplitude values\n",
    "    data_scrambled_fft = data_fft_amp * np.exp(1j * data_fft_angle_rand)  # returns complex FFT coefficients\n",
    "\n",
    "    # do inverse FFT\n",
    "    data_scrambled = np.fft.irfft(data_scrambled_fft, n=data_matrix.shape[0], axis=0)\n",
    "\n",
    "    # transpose if necessary\n",
    "    if transposeFlag:\n",
    "        data_scrambled = np.transpose(data_scrambled)\n",
    "\n",
    "    return data_scrambled\n",
    "\n",
    "\n",
    "def phase_scrambling_tests(data_matrix, data_scrambled, fft_axis=0, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Tests for the phase_scrambling function:\n",
    "    (1) compare original FFT amplitudes to scrambled data FFT amplitudes\n",
    "    (2) compare original covariance matrix to scrambled data covariance matrix\n",
    "    (3) check if correlations between original and corresponding scrambled time series are around 0\n",
    "    In the third test, we expect the correlation coefficients to show a normal\n",
    "    distribution around 0, with a \"small\" std. To keep things simple, we do not fit\n",
    "    a normal distribution or try a formal statistical test, but plot the histogram\n",
    "    of the values and decide the test on the basis of the mean and median values\n",
    "    (we check if they are \"close\" to zero, meaning < 0.05).\n",
    "    IMPORTANT: For the second check we calculate the covariance matrices, so for really large data\n",
    "    (e.g. tens of thousands of variables) consider the memory requirements of that step\n",
    "    (~ 1.6 GB for 10^3 variables, considering we need two matrices). The function does not have\n",
    "    internal checks for that.\n",
    "    Inputs:\n",
    "    data_matrix:        2D numpy array of reals. Original data set before phase scrambling.\n",
    "                        Time series (Vars) X samples by default, set fft_axis if samples X time series.\n",
    "    data_scrambled:     2D numpy array of reals, phase scrambled version of \"data_matrix\".\n",
    "                        Same size and shape as \"data_matrix\".\n",
    "    fft_axis:           Axis along which FFT / iFFT is calculated. Defaults to 0,\n",
    "                        meaning that FFT is calculated across rows (= each column is a separate time series / var).\n",
    "    epsilon:            Numeric value, threshold for machine accuracy. Tests 1 and 2 are considered \"passed\"\n",
    "                        (that is, output \"test_results\" values set to True), if numeric inaccuracies\n",
    "                        are below the threshold \"epsilon\". Defaults to 1e-10.\n",
    "    Output:\n",
    "    test_results:       List of booleans, 3-element long. Each boolean value corresponds\n",
    "                        to pass (True) / fail (False) on a test.\n",
    "                        The three values correspond to the (1) FFT amplitude test, (2) covariance matrix test,\n",
    "                        and (3) correlations test.\n",
    "                        Returns 0 if input checks failed.\n",
    "    \"\"\"\n",
    "\n",
    "    # input checks\n",
    "    if not isinstance(data_matrix, np.ndarray) or len(data_matrix.shape) != 2 or np.iscomplex(data_matrix).any():\n",
    "        print('Input arg \"data_matrix\" should be a 2D numpy array of reals!')\n",
    "        return 0\n",
    "    if type(data_matrix) != type(data_scrambled) or data_matrix.shape != data_scrambled.shape or np.iscomplex(data_scrambled).any():\n",
    "        print('Input arg \"data_scrambled\" should be a 2D numpy array of reals, with the same shape as \"data_matrix\"!')\n",
    "        return 0\n",
    "    if fft_axis not in [0, 1]:\n",
    "        print('Input arg \"fft_axis\" should be 0 or 1!')\n",
    "        return 0\n",
    "\n",
    "    # if fft_axis != 0, transpose the data\n",
    "    if fft_axis == 1:\n",
    "        data_matrix = np.transpose(data_matrix)\n",
    "        data_scrambled = np.transpose(data_scrambled)\n",
    "\n",
    "    # init output list\n",
    "    test_results = [False, False, False]\n",
    "\n",
    "    # Check FFT component amplitudes / magnitudes. They should be the same, with differences only due to numeric inaccuracies\n",
    "    # do forward FFT, use version for reals, treat data as if vars were in columns\n",
    "    data_fft = np.fft.rfft(data_matrix, axis=0)\n",
    "    data_scrambled_fft = np.fft.rfft(data_scrambled, axis=0)\n",
    "    # compare magnitudes\n",
    "    amp_diffs = np.abs(data_fft)-np.abs(data_scrambled_fft)\n",
    "    print('Maximum difference between FFT component magnitudes: {:.3e}'.format(amp_diffs.max()))\n",
    "    # set relevant output to True if passed the test\n",
    "    if not (amp_diffs>epsilon).any():\n",
    "        test_results[0] = True\n",
    "        print('First test passed, original and scrambled data have matching FFT component amplitudes.')\n",
    "    else:\n",
    "        print('First test failed, found substantial difference\\n' +\n",
    "              'between original and scrambled data FFT component magnitudes.')\n",
    "\n",
    "    # Check the covariance matrices\n",
    "    data_cov = np.cov(data_matrix, rowvar=False)\n",
    "    data_scrambled_cov = np.cov(data_scrambled, rowvar=False)\n",
    "    maxDiff = (data_cov-data_scrambled_cov).flatten().max()  # maximum difference\n",
    "    print('Maximum difference between covariance matrices: {:.3e}'.format(maxDiff))\n",
    "    # set relevant output to True if passed the test\n",
    "    if maxDiff <= epsilon:\n",
    "        test_results[1] = True\n",
    "        print('Second test passed, original and scrambled data have matching covariance structures.')\n",
    "    else:\n",
    "        print('Second test failed, found substantial difference\\n' +\n",
    "              'between original and scrambled data covariance structures.')\n",
    "\n",
    "    # Check the correlations across original and scrambled vars\n",
    "    ccoeffs = fastColumnCorr(data_matrix, data_scrambled)\n",
    "    # if the mean and median are close to zero (<0.05) we consider that a success\n",
    "    tmp = mplot.hist(ccoeffs, bins=data_matrix.shape[1]//40)\n",
    "    if np.mean(ccoeffs) < 0.05 and np.median(ccoeffs) < 0.05:\n",
    "        test_results[2] = True\n",
    "        print('Third test passed, correlation coefficients group around 0.\\n' +\n",
    "              ' Look at the histogram for further details.')\n",
    "    else:\n",
    "        print('Third test failed, correlation coefficients seem to be biased.\\n' +\n",
    "              'Look at the histogram for further details.')\n",
    "\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ISC functions\n",
    "\n",
    "#OLS - COMPARE WITH sklearn.linear_model.LinearRegression **********************************\n",
    "def reg_m(y, x):\n",
    "    x = np.array(x).T\n",
    "    x = sm.add_constant(x)\n",
    "    results = sm.OLS(endog=y, exog=x).fit()\n",
    "    return results\n",
    "\n",
    "#make 2d X-matrix with variably lagged timeseries [TRs x 2*maxT+1]\n",
    "def make2dVshift(data,maxT):\n",
    "    \n",
    "    \"\"\"\n",
    "    make2dVshift -- make 2d X-matrix with variably lagged timeseries [TRs x 2*maxT+1]\n",
    "    INPUTS:\n",
    "    data = a [TRs x 1] timeseries vector\n",
    "    maxT = absolute value of maximum lag to include in the model [TRs]\n",
    "    OUTPUTS:\n",
    "    vshift = the X-matrix for voxelwise linear models using variably lagged timeseries [TRs x 2*maxT+1]\n",
    "    \"\"\"\n",
    "    vShift = np.empty([len(data), 2*maxT+1]) #preallocate [TRs x shifts]\n",
    "    for i in list(range(-maxT,maxT+1)):\n",
    "        if i < 0:\n",
    "            vShift[:,i+maxT] = np.hstack((data[list(range(-i,data.shape[0]))],np.zeros(-i)))\n",
    "        elif i == 0:\n",
    "            vShift[:,i+maxT] = data\n",
    "        else:\n",
    "            vShift[:,i+maxT] = np.hstack((np.zeros(i), data[list(range(0,data.shape[0]-i))]))\n",
    "    \n",
    "    return vShift\n",
    "\n",
    "#make 3d X-matrix with variably lagged timeseries [TRs x voxels x 2*maxT+1]\n",
    "def make3dVshift(data,maxT):\n",
    "    \n",
    "    \"\"\"\n",
    "    make3dVshift -- make 3d X-matrix with variably lagged timeseries\n",
    "    INPUTS:\n",
    "    data = a [TRs x voxels] timeseries matrix\n",
    "    maxT = absolute value of maximum lag to include in the model [TRs]\n",
    "    OUTPUTS:\n",
    "    vshift = horizontally stacked X-matrices for voxelwise linear models using variably lagged timeseries [TRs x voxels x 2*maxT+1]\n",
    "    \"\"\"\n",
    "    #initialize real time-lagged dataset [TRs x voxels x 2*maxT+1]\n",
    "    vShift = np.empty([data.shape[0],data.shape[1],2*maxT+1])\n",
    "\n",
    "    #if it's the first iteration, then get the real time lagged dataset\n",
    "    for i in list(range(-maxT,maxT+1)): #for each lag\n",
    "\n",
    "        if i < 0: #if no lag\n",
    "            vShift[:,:,i+maxT] = np.vstack((data[list(range(-i,data.shape[0])),:], np.zeros((-i,data.shape[1]))))\n",
    "        elif i == 0:\n",
    "            vShift[:,:,i+maxT] = data\n",
    "        else:\n",
    "            vShift[:,:,i+maxT] = np.vstack((np.zeros((i,data.shape[1])), data[list(range(0,data.shape[0]-i)),:]))\n",
    "    \n",
    "    return vShift\n",
    "\n",
    "def voxWrapper(vShift3D,listener,VOX):\n",
    "    \"\"\"\n",
    "    INPUTS\n",
    "    vShift3D: ___\n",
    "    listener: listener time series\n",
    "    VOX: voxel index\n",
    "\n",
    "    OUTPUTS\n",
    "    b: beta\n",
    "    Rsq: R^2\n",
    "    F: F-test\n",
    "    pF: F-test p-value \n",
    "    \"\"\"\n",
    "    #get voxel-specific X-matrix from the non-scrambled data in 2D\n",
    "    X = np.reshape(vShift3D[:,VOX,:],(vShift3D.shape[0],vShift3D.shape[2]))\n",
    "\n",
    "    #solve linear model vShift*b=y where y is the vector from listener's data\n",
    "    model = reg_m(listener[:,VOX].T, X.T)\n",
    "    \n",
    "    b = model.params[list(range(1,len(model.params)))]\n",
    "    Rsq = model.rsquared\n",
    "    F = model.fvalue\n",
    "    pF = model.f_pvalue\n",
    "\n",
    "    return b, Rsq, F, pF\n",
    "\n",
    "def voxWrapperPerm(vShift3D_scr,listener,Rperm,VOX):\n",
    "    \"\"\"\n",
    "    INPUTS\n",
    "    vShift3D_scr: scrambled ___\n",
    "    listener: listener time series\n",
    "    Rperm: preallocated array for permutation test R^2 values [permutations x voxels]\n",
    "    VOX: voxel index\n",
    "\n",
    "    OUTPUT\n",
    "    pP_Rsq: p-value from [1 x voxels]\n",
    "    \"\"\"\n",
    "    #get voxel-specific X-matrix from the scrambled data in 2D\n",
    "    X = np.reshape(vShift3D_scr[:,VOX,:],(vShift3D_scr.shape[0],vShift3D_scr.shape[2]))\n",
    "\n",
    "    #solve linear model vShift*b=y where y is the vector from listener's data\n",
    "    model = reg_m(listener[:,VOX].T, X.T)\n",
    "\n",
    "    return model.rsquared\n",
    "    \n",
    "#ISC computation\n",
    "def couplingFMRI(speaker, listener, maxT, fitPermuts, method):\n",
    "\n",
    "    #no. of voxels and TRs\n",
    "    voxelN = speaker.shape[1]\n",
    "    trN = speaker.shape[0]\n",
    "\n",
    "    #preallocate results matrices\n",
    "    b = np.empty([2*maxT+1, voxelN])\n",
    "    Rsq = np.empty([voxelN]);\n",
    "    F = np.empty([voxelN]);\n",
    "    pF = np.empty([voxelN]);\n",
    "    pP_F = np.empty([voxelN]);\n",
    "\n",
    "    #print('Data dimensions: ' + str(trN) + ' X ' + str(voxelN));\n",
    "    print('Modeling listener data using lagged time series from speaker...');\n",
    "\n",
    "    if method == 0: #original method\n",
    "\n",
    "        #For each voxel...\n",
    "        for VOX in list(range(0,voxelN)):\n",
    "\n",
    "            #get X matrix of time-shifted speaker timeseries\n",
    "            vShift = make2dVshift(speaker[:,VOX],maxT)\n",
    "\n",
    "            #solve linear model vShift*b=y where y is the vector from listener's data\n",
    "            model = reg_m(listener[:,VOX].T, vShift.T)\n",
    "            b[:,VOX] = model.params[list(range(1,len(model.params)))]\n",
    "            Rsq[VOX] = model.rsquared\n",
    "            F[VOX] = model.fvalue\n",
    "            pF[VOX] = model.f_pvalue\n",
    "\n",
    "            #occassional feedback\n",
    "            if ((VOX + 1) % 10000 == 0) | (voxelN < 10000 & VOX == voxelN-1):\n",
    "                print('\\nFinished with voxel no. ' + str(VOX + 1))\n",
    "\n",
    "            #run permutation test if selected\n",
    "            if fitPermuts > 0:\n",
    "\n",
    "                #preallocate\n",
    "                pP_Rsq = np.empty([voxelN]);\n",
    "                \n",
    "                for PERM in list(range(0,fitPermuts)):\n",
    "                    \n",
    "                    #make time-lagged X-matrices without scrambling the speaker timeseries\n",
    "                    vShift2D = make2dVshift(speaker[:,VOX],maxT)\n",
    "                    \n",
    "                    #scramble the time series\n",
    "                    X = phase_scrambling(vShift2D)\n",
    "                    X = np.vstack((vShift_scr,vShift_scr[0,])) #JD HACK because row nums not preserved\n",
    "\n",
    "                    #solve linear model vShift*b=y where y is the vector from listener's data\n",
    "                    model = reg_m(listener[:,VOX].T, X.T)\n",
    "                    Rperm[PERM,VOX] = model.rsquared\n",
    "                    \n",
    "                    #get permutation test R^2 p-value\n",
    "                    if PERM == firPermuts - 1: #if we're on the last permutation...\n",
    "                        pP_Rsq[VOX] = len(Rperm[:,VOX][Rperm[:,VOX] > Rsq[VOX]]) / float(fitPermuts)\n",
    "\n",
    "            else:\n",
    "                if VOX == 0: #only need to do this once\n",
    "                    pP_Rsq = None\n",
    "\n",
    "    else: #new method\n",
    "\n",
    "        if fitPermuts > 0:\n",
    "            \n",
    "            #preallocate arrays for Rsq and F-statistics from permutation test\n",
    "            pP_Rsq = np.empty([voxelN]);\n",
    "            Rperm = np.empty([fitPermuts,voxelN])\n",
    "\n",
    "            for PERM in list(range(0,fitPermuts)):\n",
    "\n",
    "                #if it's the first permutation, set up the non-scrambled time series\n",
    "                if PERM == 0:\n",
    "\n",
    "                    #make time-lagged X-matrices without scrambling the speaker timeseries\n",
    "                    vShift3D = make3dVshift(speaker,maxT)\n",
    "\n",
    "                #scramble the time series\n",
    "                speaker_scr = phase_scrambling(speaker)\n",
    "                \n",
    "\n",
    "                #make time-lagged X-matrices\n",
    "                vShift3D_scr = make3dVshift(speaker_scr,maxT)\n",
    "\n",
    "                #if using joblib for voxelwise computations...\n",
    "                if voxParallel == 1:\n",
    "                    \n",
    "                    #non-scrambled\n",
    "                    if PERM == 0:\n",
    "                        \n",
    "                        #run ISC for each voxel using joblib\n",
    "                        tmp = Parallel(n_jobs=numJobs)(delayed(voxWrapper)(vShift3D,listener,VOX) for VOX in range(voxelN))\n",
    "                        \n",
    "                        #reformat\n",
    "                        for VOX in range(voxelN):\n",
    "                            b[:,VOX] = tmp[VOX][0]\n",
    "                            Rsq[VOX] = tmp[VOX][1]\n",
    "                            F[VOX] = tmp[VOX][2]\n",
    "                            pF[VOX] = tmp[VOX][3]\n",
    "                        \n",
    "                    #scrambled\n",
    "                    pP_Rsq_tmp = Parallel(n_jobs=numJobs)(delayed(voxWrapperPerm)(vShift3D_scr,listener,VOX) for VOX in range(voxelN))\n",
    "                    Rperm[PERM,:] = pP_Rsq_tmp\n",
    "                    \n",
    "                    #get p-value from permutated Rsq and F values\n",
    "                    if PERM == fitPermuts-1: #if it's the last permutation...\n",
    "                        pP_Rsq = Parallel(n_jobs=numJobs)(delayed(len(Rperm[:,VOX][Rperm[:,VOX] > Rsq[VOX]]) / float(fitPermuts))(Rperm,fitPermuts,VOX) for VOX in range(voxelN))\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    #for each voxel...\n",
    "                    for VOX in list(range(0,voxelN)):\n",
    "\n",
    "                        #if it's the first permutation... fit the voxelwise models to the non-scrambled data\n",
    "                        if PERM == 0:\n",
    "\n",
    "                            #get voxel-specific X-matrix from the non-scrambled data in 2D\n",
    "                            X = np.reshape(vShift3D[:,VOX,:],(vShift3D.shape[0],vShift3D.shape[2]))\n",
    "\n",
    "                            #solve linear model vShift*b=y where y is the vector from listener's data\n",
    "                            model = reg_m(listener[:,VOX].T, X.T)\n",
    "                            b[:,VOX] = model.params[list(range(1,len(model.params)))]\n",
    "                            Rsq[VOX] = model.rsquared\n",
    "                            F[VOX] = model.fvalue\n",
    "                            pF[VOX] = model.f_pvalue\n",
    "\n",
    "                        #get voxel-specific X-matrix from the scrambled data in 2D\n",
    "                        X = np.reshape(vShift3D_scr[:,VOX,:],(vShift3D_scr.shape[0],vShift3D_scr.shape[2]))\n",
    "\n",
    "                        #solve linear model vShift*b=y where y is the vector from listener's data\n",
    "                        model = reg_m(listener[:,VOX].T, X.T)\n",
    "                        Rperm[PERM,VOX] = model.rsquared\n",
    "\n",
    "                        #get p-value from permutated Rsq and F values\n",
    "                        if PERM == fitPermuts-1: #if it's the last permutation...\n",
    "                            pP_Rsq[VOX] = len(Rperm[:,VOX][Rperm[:,VOX] > Rsq[VOX]]) / float(fitPermuts)\n",
    "                        \n",
    "        else: \n",
    "            \n",
    "            #make time-lagged X-matrices without scrambling the speaker timeseries\n",
    "            vShift3D = make3dVshift(speaker,maxT)\n",
    "            \n",
    "            #if using joblib for voxelwise computations...\n",
    "            if voxParallel == 1:\n",
    "                \n",
    "                #run ISC for each voxel using joblib\n",
    "                tmp = Parallel(n_jobs=numJobs)(delayed(voxWrapper)(vShift3D,listener,VOX) for VOX in range(voxelN))\n",
    "                \n",
    "                #reformat\n",
    "                for VOX in range(voxelN):\n",
    "                    b[:,VOX] = tmp[VOX][0]\n",
    "                    Rsq[VOX] = tmp[VOX][1]\n",
    "                    F[VOX] = tmp[VOX][2]\n",
    "                    pF[VOX] = tmp[VOX][3]\n",
    "                \n",
    "            else: \n",
    "                \n",
    "                #for each voxel...\n",
    "                for VOX in list(range(0,voxelN)):\n",
    "\n",
    "                    #get voxel-specific X-matrix from the non-scrambled data in 2D\n",
    "                    X = np.reshape(vShift3D[:,VOX,:],(vShift3D.shape[0],vShift3D.shape[2]))\n",
    "\n",
    "                    #solve linear model vShift*b=y where y is the vector from listener's data\n",
    "                    model = reg_m(listener[:,VOX].T, X.T)\n",
    "                    b[:,VOX] = model.params[list(range(1,len(model.params)))]\n",
    "                    Rsq[VOX] = model.rsquared\n",
    "                    F[VOX] = model.fvalue\n",
    "                    pF[VOX] = model.f_pvalue\n",
    "\n",
    "            pP_Rsq = None\n",
    "\n",
    "    return b, Rsq, F, pF, pP_Rsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Loop over DBIC participants\n",
    "pseudoCounter = 0;\n",
    "realCounter = 0;\n",
    "pairCounter = 0;\n",
    "\n",
    "#preallocate speaker timeseries arrays\n",
    "sData = [[]]*4; \n",
    "\n",
    "#preallocate listener timeseries arrays\n",
    "lData = [[]]*4; \n",
    "\n",
    "#define some index mapping variables\n",
    "rowMap = [0,1,0,1]\n",
    "ijMap = [0,0,1,1]\n",
    "\n",
    "for dbicPairN in dbicSubs: #for each DBIC subject...\n",
    "    \n",
    "    #clear the DBIC arrays within sData and lData to make sure nothing gets recycled between participants\n",
    "    for COND in [1,3]:\n",
    "        sData[COND] = np.empty([totalTRs,len(voxelCoords)])\n",
    "    for COND in [0,2]:\n",
    "        lData[COND] = np.empty([totalTRs,len(voxelCoords)])\n",
    "    \n",
    "    ######################\n",
    "    ### load DBIC data ###\n",
    "    ######################\n",
    "    \n",
    "    #get dbicSub ID and runN\n",
    "    dbicSub = pairsAndRuns['DBIC'][dbicPairN] #e.g., 'sid000007'\n",
    "    dbicRunInd = pairsAndRuns['ind_run'][dbicPairN]\n",
    "    dbicRunJoint = pairsAndRuns['joint_run'][dbicPairN]\n",
    "    \n",
    "    #indicate that we're starting on a new DBIC participant\n",
    "    print('\\nloading data for DBIC subject ' + str(dbicPairN + 1) + ', ' + dbicSub + '...')\n",
    "    \n",
    "    #get file names\n",
    "    if local == 1: #for JD debugging locally -- will eventually remove\n",
    "        \n",
    "        #independent DBIC speaker\n",
    "        dbicFileSpeaker_ind = '/Users/jeffreyknotts/Documents/MATLAB/Wheatley/isc_test/sub-' + dbicSub + \\\n",
    "        '_ses-pair0' + str(dbicPairN + 1) + '_task-storytelling' + str(dbicRunInd) + '_run-0' + \\\n",
    "        str(dbicRunInd) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_speaker.mat'  #[TRs x voxels]\n",
    "        \n",
    "        #independent DBIC listener\n",
    "        dbicFileListener_ind = '/Users/jeffreyknotts/Documents/MATLAB/Wheatley/isc_test/sub-' + dbicSub + \\\n",
    "        '_ses-pair0' + str(dbicPairN + 1) + '_task-storytelling' + str(dbicRunInd) + '_run-0' + \\\n",
    "        str(dbicRunInd) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_listener.mat'  #[TRs x voxels]\n",
    "        \n",
    "        #joint DBIC speaker\n",
    "        dbicFileSpeaker_joint = '/Users/jeffreyknotts/Documents/MATLAB/Wheatley/isc_test/sub-' + dbicSub + \\\n",
    "        '_ses-pair0' + str(dbicPairN + 1) + '_task-storytelling' + str(dbicRunJoint) + '_run-0' + \\\n",
    "        str(dbicRunJoint) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_speaker.mat'  #[TRs x voxels]\n",
    "        \n",
    "        #joint DBIC listener\n",
    "        dbicFileListener_joint = '/Users/jeffreyknotts/Documents/MATLAB/Wheatley/isc_test/sub-' + dbicSub + \\\n",
    "        '_ses-pair0' + str(dbicPairN + 1) + '_task-storytelling' + str(dbicRunJoint) + '_run-0' + \\\n",
    "        str(dbicRunJoint) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_listener.mat'  #[TRs x voxels]\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        #independent DBIC speaker\n",
    "        dbicFileSpeaker_ind = '/flash/wheatley/adamb/hyperscanning_DBIC_ses2/sub-' + dbicSub + \\\n",
    "        '_fmriprep/fmriprep/sub-' + dbicSub + '/ses-pair0' + str(dbicPairN + 1) + '/func/' + \\\n",
    "        'sub-' + dbicSub + '_ses-pair0' + str(dbicPairN + 1) + '_task-storytelling' + str(dbicRunInd) + '_run-0' + \\\n",
    "        str(dbicRunInd) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_speaker.mat'  #[TRs x voxels]\n",
    "        \n",
    "        #independent DBIC listener\n",
    "        dbicFileListener_ind = '/flash/wheatley/adamb/hyperscanning_DBIC_ses2/sub-' + dbicSub + \\\n",
    "        '_fmriprep/fmriprep/sub-' + dbicSub + '/ses-pair0' + str(dbicPairN + 1) + '/func/' + \\\n",
    "        'sub-' + dbicSub + '_ses-pair0' + str(dbicPairN + 1) + '_task-storytelling' + str(dbicRunInd) + '_run-0' + \\\n",
    "        str(dbicRunInd) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_listener.mat'  #[TRs x voxels]\n",
    "        \n",
    "        #joint DBIC speaker\n",
    "        dbicFileSpeaker_joint = '/flash/wheatley/adamb/hyperscanning_DBIC_ses2/sub-' + dbicSub + \\\n",
    "        '_fmriprep/fmriprep/sub-' + dbicSub + '/ses-pair0' + str(dbicPairN + 1) + '/func/' + \\\n",
    "        'sub-' + dbicSub + '_ses-pair0' + str(dbicPairN + 1) + '_task-storytelling' + str(dbicRunJoint) + '_run-0' + \\\n",
    "        str(dbicRunJoint) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_speaker.mat'  #[TRs x voxels]\n",
    "        \n",
    "        #joint DBIC listener\n",
    "        dbicFileListener_joint = '/flash/wheatley/adamb/hyperscanning_DBIC_ses2/sub-' + dbicSub + \\\n",
    "        '_fmriprep/fmriprep/sub-' + dbicSub + '/ses-pair0' + str(dbicPairN + 1) + '/func/' + \\\n",
    "        'sub-' + dbicSub + '_ses-pair0' + str(dbicPairN + 1) + '_task-storytelling' + str(dbicRunJoint) + '_run-0' + \\\n",
    "        str(dbicRunJoint) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_listener.mat'  #[TRs x voxels]\n",
    "        \n",
    "        \n",
    "    #load timeseries for (D)BIC (S)peaker in the (I)ndependent condition\n",
    "    if 'ts_DSI' in locals(): #if the ts_DSI variable already exists...\n",
    "        del ts_DSI #delete it to make sure we don't have data leaking between participants\n",
    "    if os.path.isfile(dbicFileSpeaker_ind):\n",
    "        dummy = sio.loadmat(dbicFileSpeaker_ind) #load data\n",
    "        sData[1] = dummy['dbicSpeaker'][:,voxelCoords] #get timeseries data \n",
    "        #ts_DSI = dummy['dbicSpeaker'] #get timeseries data \n",
    "        del dummy\n",
    "        \n",
    "    #load timeseries for (D)BIC (L)istener in the (I)ndependent condition\n",
    "    if 'ts_DLI' in locals(): #if the ts_DLI variable already exists...\n",
    "        del ts_DLI #delete it to make sure we don't have data leaking between participants\n",
    "    if os.path.isfile(dbicFileListener_ind):\n",
    "        dummy = sio.loadmat(dbicFileListener_ind) #load data\n",
    "        lData[0] = dummy['dbicListener'][:,voxelCoords] #get timeseries data\n",
    "        #ts_DLI = dummy['dbicListener'] #get timeseries data\n",
    "        del dummy\n",
    "        \n",
    "    #load timeseries for (D)BIC (S)peaker in the (J)oint condition\n",
    "    if 'ts_DSJ' in locals(): #if the ts_DSJ variable already exists...\n",
    "        del ts_DSJ #delete it to make sure we don't have data leaking between participants\n",
    "    if os.path.isfile(dbicFileSpeaker_joint):\n",
    "        dummy = sio.loadmat(dbicFileSpeaker_joint) #load data\n",
    "        sData[3] = dummy['dbicSpeaker'][:,voxelCoords] #get time series data\n",
    "        #ts_DSJ = dummy['dbicSpeaker'] #get time series data\n",
    "        del dummy\n",
    "        \n",
    "    #load timeseries for (D)BIC (L)istener in the (J)oint condition\n",
    "    if 'ts_DLJ' in locals(): #if the ts_DLJ variable already exists...\n",
    "        del ts_DLJ #delete it to make sure we don't have data leaking between participants\n",
    "    if os.path.isfile(dbicFileListener_joint):\n",
    "        dummy = sio.loadmat(dbicFileListener_joint) #load data\n",
    "        lData[2] = dummy['dbicListener'][:,voxelCoords] #get time series data\n",
    "        #ts_DLJ = dummy['dbicListener'] #get time series data\n",
    "        del dummy\n",
    "\n",
    "    \n",
    "    #Loop over CBS participants\n",
    "    for cbsPairN in cbsSubs:\n",
    "        \n",
    "        #clear the CBS arrays within sData and lData to make sure nothing gets recycled between participants\n",
    "        for COND in [0,2]:\n",
    "            sData[COND] = np.empty([totalTRs,len(voxelCoords)]) \n",
    "        for COND in [1,3]:\n",
    "            lData[COND] = np.empty([totalTRs,len(voxelCoords)])\n",
    "\n",
    "        #####################\n",
    "        ### load CBS data ###\n",
    "        #####################\n",
    "        \n",
    "        pairType = 0; #for adding to time.pairs below\n",
    "        \n",
    "        cbsSub = pairsAndRuns['CBS'][cbsPairN] #e.g., 'hid000002'\n",
    "        cbsRunInd = pairsAndRuns['ind_run'][cbsPairN]\n",
    "        cbsRunJoint = pairsAndRuns['joint_run'][cbsPairN]\n",
    "        \n",
    "        #indicate that we're starting on a new DBIC participant\n",
    "        print('\\nloading data for CBS subject ' + str(cbsPairN + 1) + ', ' + cbsSub + '...')\n",
    "        \n",
    "        #get file names\n",
    "        if local == 1: #for JD debugging locally -- will eventually remove\n",
    "\n",
    "            #independent CBS speaker\n",
    "            cbsFileSpeaker_ind = '/Users/jeffreyknotts/Documents/MATLAB/Wheatley/isc_test/sub-' + cbsSub + \\\n",
    "            '_ses-pair0' + str(cbsPairN + 1) + '_task-storytelling' + str(cbsRunInd) + '_run-0' + \\\n",
    "            str(cbsRunInd) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_speaker.mat'  #[TRs x voxels]\n",
    "\n",
    "            #independent CBS listener\n",
    "            cbsFileListener_ind = '/Users/jeffreyknotts/Documents/MATLAB/Wheatley/isc_test/sub-' + cbsSub + \\\n",
    "            '_ses-pair0' + str(cbsPairN + 1) + '_task-storytelling' + str(cbsRunInd) + '_run-0' + \\\n",
    "            str(cbsRunInd) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_listener.mat'  #[TRs x voxels]\n",
    "\n",
    "            #joint CBS speaker\n",
    "            cbsFileSpeaker_joint = '/Users/jeffreyknotts/Documents/MATLAB/Wheatley/isc_test/sub-' + cbsSub + \\\n",
    "            '_ses-pair0' + str(cbsPairN + 1) + '_task-storytelling' + str(cbsRunJoint) + '_run-0' + \\\n",
    "            str(cbsRunJoint) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_speaker.mat'  #[TRs x voxels]\n",
    "\n",
    "            #joint CBS listener\n",
    "            cbsFileListener_joint = '/Users/jeffreyknotts/Documents/MATLAB/Wheatley/isc_test/sub-' + cbsSub + \\\n",
    "            '_ses-pair0' + str(cbsPairN + 1) + '_task-storytelling' + str(cbsRunJoint) + '_run-0' + \\\n",
    "            str(cbsRunJoint) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_listener.mat'  #[TRs x voxels]\n",
    "\n",
    "        else:\n",
    "\n",
    "            #independent CBS speaker\n",
    "            cbsFileSpeaker_ind = '/flash/wheatley/adamb/hyperscanning_CBS/sub-' + cbsSub + \\\n",
    "            '_fmriprep/fmriprep/sub-' + cbsSub + '/ses-pair0' + str(cbsPairN + 1) + '/func/' + \\\n",
    "            'sub-' + cbsSub + '_ses-pair0' + str(cbsPairN + 1) + '_task-storytelling' + str(cbsRunInd) + '_run-0' + \\\n",
    "            str(cbsRunInd) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_speaker.mat'  #[TRs x voxels]\n",
    "            \n",
    "            #independent CBS listener\n",
    "            cbsFileListener_ind = '/flash/wheatley/adamb/hyperscanning_CBS/sub-' + cbsSub + \\\n",
    "            '_fmriprep/fmriprep/sub-' + cbsSub + '/ses-pair0' + str(cbsPairN + 1) + '/func/' + \\\n",
    "            'sub-' + cbsSub + '_ses-pair0' + str(cbsPairN + 1) + '_task-storytelling' + str(cbsRunInd) + '_run-0' + \\\n",
    "            str(cbsRunInd) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_listener.mat'  #[TRs x voxels]\n",
    "\n",
    "            #joint CBS speaker\n",
    "            cbsFileSpeaker_joint = '/flash/wheatley/adamb/hyperscanning_CBS/sub-' + cbsSub + \\\n",
    "            '_fmriprep/fmriprep/sub-' + cbsSub + '/ses-pair0' + str(cbsPairN + 1) + '/func/' + \\\n",
    "            'sub-' + cbsSub + '_ses-pair0' + str(cbsPairN + 1) + '_task-storytelling' + str(cbsRunJoint) + '_run-0' + \\\n",
    "            str(cbsRunJoint) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_speaker.mat'  #[TRs x voxels]\n",
    "\n",
    "            #joint CBS listener\n",
    "            cbsFileListener_joint = '/flash/wheatley/adamb/hyperscanning_CBS/sub-' + cbsSub + \\\n",
    "            '_fmriprep/fmriprep/sub-' + cbsSub + '/ses-pair0' + str(cbsPairN + 1) + '/func/' + \\\n",
    "            'sub-' + cbsSub + '_ses-pair0' + str(cbsPairN + 1) + '_task-storytelling' + str(cbsRunJoint) + '_run-0' + \\\n",
    "            str(cbsRunJoint) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_listener.mat'  #[TRs x voxels]\n",
    "\n",
    "            \n",
    "        #load timeseries for (C)BS (S)peaker in the (I)ndependent condition\n",
    "        if 'ts_CSI' in locals(): #if the ts_CSI variable already exists...\n",
    "            del ts_CSI #delete it to make sure we don't have data leaking between participants\n",
    "        if os.path.isfile(cbsFileSpeaker_ind):\n",
    "            dummy = sio.loadmat(cbsFileSpeaker_ind) #load data\n",
    "            sData[0] = dummy['cbsSpeaker'][:,voxelCoords] #get time series data\n",
    "            #ts_CSI = dummy['cbsSpeaker'] #get time series data\n",
    "            del dummy\n",
    "            \n",
    "        #load timeseries for (C)BS (L)istener in the (I)ndependent condition\n",
    "        if 'ts_CLI' in locals(): #if the ts_CLI variable already exists...\n",
    "            del ts_CLI #delete it to make sure we don't have data leaking between participants\n",
    "        if os.path.isfile(cbsFileListener_ind):\n",
    "            dummy = sio.loadmat(cbsFileListener_ind) #load data\n",
    "            lData[1] = dummy['cbsListener'][:,voxelCoords] #get time series data\n",
    "            #ts_CLI = dummy['cbsListener'] #get time series data\n",
    "            del dummy\n",
    "        \n",
    "        #load timeseries for (C)BS (S)peaker in the (J)oint condition\n",
    "        if 'ts_CSJ' in locals(): #if the ts_CSJ variable already exists...\n",
    "            del ts_CSJ #delete it to make sure we don't have data leaking between participants\n",
    "        if os.path.isfile(cbsFileSpeaker_joint):\n",
    "            dummy = sio.loadmat(cbsFileSpeaker_joint) #load data\n",
    "            sData[2] = dummy['cbsSpeaker'][:,voxelCoords] #get time series data\n",
    "            #ts_CSJ = dummy['cbsSpeaker'] #get time series data\n",
    "            del dummy\n",
    "        \n",
    "        #load timeseries for (C)BS (L)istener in the (J)oint condition\n",
    "        if 'ts_CLJ' in locals(): #if the ts_CLJ variable already exists...\n",
    "            del ts_CLJ #delete it to make sure we don't have data leaking between participants\n",
    "        if os.path.isfile(cbsFileListener_joint):\n",
    "            dummy = sio.loadmat(cbsFileListener_joint) #load data\n",
    "            lData[3] = dummy['cbsListener'][:,voxelCoords] #get time series data\n",
    "            #ts_CLJ = dummy['cbsListener'] #get time series data\n",
    "            del dummy\n",
    "        \n",
    "        \n",
    "        ########################\n",
    "        ### run couplingFMRI ###\n",
    "        ########################\n",
    "        \n",
    "        pairStart = time.time() #get starting time\n",
    "        print('\\n#################################################')\n",
    "        print('### starting ISC for DBIC sub ' + str(dbicPairN + 1) + ' and CBS sub ' + str(cbsPairN + 1) + ' ###')\n",
    "        print('#################################################')\n",
    "    \n",
    "        if dbicPairN == cbsPairN: #if we're dealing with a real pair...\n",
    "            \n",
    "            #Get real pair info\n",
    "            ROW = [(realCounter*2), realCounter*2+1]\n",
    "            pairMap[0][ROW,0] = dbicPairN + 1\n",
    "            pairMap[0][ROW,1] = cbsPairN + 1\n",
    "            pairMap[0][ROW,2] = [1, 0]\n",
    "            \n",
    "            #Loop over rolling windows...\n",
    "            for STEP in list(range(numSteps)): #for each window...\n",
    "                    \n",
    "                #get TRs to use in current window\n",
    "                TRs = list(range(stepSize * STEP,stepSize * STEP + winTRs)); #make sure to start at ZERO here\n",
    "                    \n",
    "                #estimate remaining time based on current estimate of mean ISC duration\n",
    "                if pairCounter == 0:\n",
    "                    timeString = 'lets wait and see how long the first ISC takes...'\n",
    "                else:\n",
    "                    estTimeRemain = pairsRemaining * meanISCdur - (meanISCdur / numSteps)*STEP\n",
    "                    hrs = math.floor(estTimeRemain / 60)\n",
    "                    minFloat = estTimeRemain % 60\n",
    "                    mins = math.floor(minFloat)\n",
    "                    secs = round((minFloat - mins)*60)\n",
    "                    if hrs > 0:\n",
    "                        timeString = str(hrs) + ' hr ' + str(mins) + ' min ' + str(secs) + ' s' \n",
    "                    else:\n",
    "                        timeString = str(mins) + ' min ' + str(secs) + ' s'\n",
    "                            \n",
    "                print('\\n%%%%%%%% Running ISC for pair ' + str(pairCounter + 1) + ' of ' + str(totalPairN) + ', step ' + str(STEP + 1) + ' of ' + str(numSteps) + ': TRs ' + str(stepSize * STEP + 1) + ':' + str(stepSize * STEP + winTRs)) #add 1 to the TRs computed in the line above for clarity in printing\n",
    "                print('%%%%%%%% estimated time remaining: ' + timeString)\n",
    "                \n",
    "                if parallel == 1: \n",
    "                    \n",
    "                    #run couplingFMRI via joblib\n",
    "                    #conditions...\n",
    "                    #COND=1: CBS speaker, DBIC listener, independent\n",
    "                    #COND=2: DBIC speaker, CBS listener, independent\n",
    "                    #COND=3: CBS speaker, DBIC listener, joint\n",
    "                    #COND=4: DBIC speaker, CBS listener, joint\n",
    "                    tmp = Parallel(n_jobs=numJobs)(delayed(couplingFMRI)(sData[COND][TRs,:], lData[COND][TRs,:], maxT, fitPermuts, method) for COND in range(4))\n",
    "                    \n",
    "                    #index couplingFMRI output to realFits array\n",
    "                    for COND in range(4):\n",
    "                        realFits[ijMap[COND]][0][ROW[rowMap[COND]],:,:,STEP] = tmp[COND][0]\n",
    "                        realFits[ijMap[COND]][1][ROW[rowMap[COND]],:,STEP] = tmp[COND][1]\n",
    "                        realFits[ijMap[COND]][2][ROW[rowMap[COND]],:,STEP] = tmp[COND][2]\n",
    "                        realFits[ijMap[COND]][3][ROW[rowMap[COND]],:,STEP] = tmp[COND][3]\n",
    "                        realFits[ijMap[COND]][4][ROW[rowMap[COND]],:,STEP] = tmp[COND][4]\n",
    "                    \n",
    "                else:\n",
    "                \n",
    "                    #run couplingFMRI\n",
    "                    #rowMap = [0,1,0,1]; ijMap = [0,0,1,1]; #MOVE OUT OF LOOPS EVENTUALLY\n",
    "                    for COND in range(4):\n",
    "                        realFits[ijMap[COND]][0][ROW[rowMap[COND]],:,:,STEP], realFits[ijMap[COND]][1][ROW[rowMap[COND]],:,STEP], realFits[ijMap[COND]][2][ROW[rowMap[COND]],:,STEP], realFits[ijMap[COND]][3][ROW[rowMap[COND]],:,STEP], realFits[ijMap[COND]][4][ROW[rowMap[COND]],:,STEP] = couplingFMRI(sData[COND][TRs,:], lData[COND][TRs,:], maxT, fitPermuts, method)\n",
    "            \n",
    "            #add one to real pair counter\n",
    "            realCounter += 1\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            #Get pseudo pair info\n",
    "            ROW = [(pseudoCounter*2), pseudoCounter*2+1]\n",
    "            pairMap[1][ROW,0] = dbicPairN + 1\n",
    "            pairMap[1][ROW,1] = cbsPairN + 1\n",
    "            pairMap[1][ROW,2] = [1, 0]\n",
    "            \n",
    "            #Loop over rolling windows...\n",
    "            for STEP in range(numSteps): #for each window...\n",
    "                \n",
    "                #get TRs to use in current window\n",
    "                TRs = list(range(stepSize * STEP,stepSize * STEP + winTRs)); #make sure to start at ZERO here\n",
    "                    \n",
    "                #estimate remaining time based on current estimate of mean ISC duration\n",
    "                if pairCounter == 0:\n",
    "                    timeString = 'lets wait and see how long the first ISC takes...'\n",
    "                else:\n",
    "                    estTimeRemain = pairsRemaining * meanISCdur - (meanISCdur / numSteps)*STEP\n",
    "                    hrs = math.floor(estTimeRemain / 60)\n",
    "                    minFloat = estTimeRemain % 60\n",
    "                    mins = math.floor(minFloat)\n",
    "                    secs = round((minFloat - mins)*60)\n",
    "                    if hrs > 0:\n",
    "                        timeString = str(hrs) + ' hr ' + str(mins) + ' min ' + str(secs) + ' s' \n",
    "                    else:\n",
    "                        timeString = str(mins) + ' min ' + str(secs) + ' s'\n",
    "                            \n",
    "                print('\\n%%%%%%%% Running ISC for pair ' + str(pairCounter + 1) + ' of ' + str(totalPairN) + ', step ' + str(STEP + 1) + ' of ' + str(numSteps) + ': TRs ' + str(stepSize * STEP + 1) + ':' + str(stepSize * STEP + winTRs)) #add 1 to the TRs computed in the line above for clarity in printing\n",
    "                print('%%%%%%%% estimated time remaining: ' + timeString)\n",
    "                \n",
    "                if parallel == 1: \n",
    "                    \n",
    "                    #run couplingFMRI via joblib\n",
    "                    #conditions...\n",
    "                    #COND=1: CBS speaker, DBIC listener, independent\n",
    "                    #COND=2: DBIC speaker, CBS listener, independent\n",
    "                    #COND=3: CBS speaker, DBIC listener, joint\n",
    "                    #COND=4: DBIC speaker, CBS listener, joint\n",
    "                    tmp = Parallel(n_jobs=numJobs)(delayed(couplingFMRI)(sData[COND][TRs,:], lData[COND][TRs,:], maxT, fitPermuts, method) for COND in range(4))\n",
    "                    \n",
    "                    #index couplingFMRI output to realFits array\n",
    "                    #rowMap = [0,1,0,1]; ijMap = [0,0,1,1]; #MOVE OUT OF LOOPS EVENTUALLY\n",
    "                    for COND in range(4):\n",
    "                        pseudoFits[ijMap[COND]][0][ROW[rowMap[COND]],:,:,STEP] = tmp[COND][0]\n",
    "                        pseudoFits[ijMap[COND]][1][ROW[rowMap[COND]],:,STEP] = tmp[COND][1]\n",
    "                        pseudoFits[ijMap[COND]][2][ROW[rowMap[COND]],:,STEP] = tmp[COND][2]\n",
    "                        pseudoFits[ijMap[COND]][3][ROW[rowMap[COND]],:,STEP] = tmp[COND][3]\n",
    "                        pseudoFits[ijMap[COND]][4][ROW[rowMap[COND]],:,STEP] = tmp[COND][4]\n",
    "                    \n",
    "                else:\n",
    "                \n",
    "                    #run couplingFMRI\n",
    "                    for COND in range(4):\n",
    "                        pseudoFits[ijMap[COND]][0][ROW[rowMap[COND]],:,:,STEP], pseudoFits[ijMap[COND]][1][ROW[rowMap[COND]],:,STEP], pseudoFits[ijMap[COND]][2][ROW[rowMap[COND]],:,STEP], pseudoFits[ijMap[COND]][3][ROW[rowMap[COND]],:,STEP], pseudoFits[ijMap[COND]][4][ROW[rowMap[COND]],:,STEP] = couplingFMRI(sData[COND][TRs,:], lData[COND][TRs,:], maxT, fitPermuts, method)\n",
    "                    \n",
    "\n",
    "            #add one to pseudo pair counter\n",
    "            pseudoCounter += 1\n",
    "        \n",
    "        #get approximate time to run couplingFMRI for current pair [min]\n",
    "        timeLog[pairCounter,0] = dbicPairN + 1 #DBIC sub index\n",
    "        timeLog[pairCounter,1] = cbsPairN + 1 #CBS sub index\n",
    "        timeLog[pairCounter,2] = round((time.time() - pairStart) / 60,1) #approximate duration of couplingFMRI for current pair [min]\n",
    "        \n",
    "        #estimate analysis duration \n",
    "        meanISCdur = np.mean(timeLog[list(range(0,pairCounter+1)),2]) #average time it takes to run couplingFMRI across all pairs that have been ruun up to this point\n",
    "        pairCounter = pairCounter + 1 #add one to total pair counter\n",
    "        pairsRemaining = totalPairN - pairCounter #get number of pairs that remain to be analyzed (for estimating time remaining above)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "endTime = time.time()\n",
    "ISCduration = (endTime - startTime) / 3600 #total duration [hrs]\n",
    "ISCduration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
