{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/jeffreyknotts/Documents/Wheatley_Lab/')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as mplot\n",
    "from numpy.random import random_sample\n",
    "from math import pi\n",
    "from math import sqrt\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#input parameters\n",
    "dbicSubs = list(range(1,3)) #using 1 and 9 as inputs gives 1:8, which will function as 2:9 according to matlab indexing\n",
    "cbsSubs = list(range(1,3))\n",
    "winTRs = 41 #window size [TRs]\n",
    "stepSize = 41 #step size [TRs] \n",
    "maxT = 6 #max TR lag to include in linear models\n",
    "voxelCoords = list(range(0,1000)) #whole brain = 1:69880 -- should add step above this that gets ROI voxel coords\n",
    "fitPermuts = 0 #0 = don't use permutation test for pair fits\n",
    "groupPermuts = 1000\n",
    "method = 1 #0=old scrambling method, 1=new method of scrambling all voxels at once\n",
    "local = 0 #for JD debugging locally -- will eventually remove\n",
    "numJobs = 8 #number of parallel processes for joblib to use\n",
    "totTRs = 615 #kind of hacky but predefining the total number of TRs that will be in each timeseries\n",
    "voxParallel = 0 #use joblib on voxelwise for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sub       DBIC        CBS  ind_run  joint_run\n",
      "0    1  sid000014  hid000001        2          1\n",
      "1    2  sid000007  hid000002        2          1\n",
      "2    3  sid000009  hid000003        2          1\n",
      "3    4  sid000560  hid000004        1          2\n",
      "4    5  sid000535  hid000005        1          2\n",
      "5    6  sid000102  hid000006        2          1\n",
      "6    7  sid000416  hid000007        2          1\n",
      "7    8  sid000499  hid000008        1          2\n",
      "8    9  sid000142  hid000009        1          2\n"
     ]
    }
   ],
   "source": [
    "#load pair and run data\n",
    "pairsAndRuns = pd.read_csv(r'/afs/.dbic.dartmouth.edu/usr/wheatley/jd/hyperscanning_pair_and_run_lookup.csv')\n",
    "print(pairsAndRuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mark starting time \n",
    "startTime = time.time()\n",
    "\n",
    "#get numbers of pairs\n",
    "realPairN = len(list(set(dbicSubs) & set(cbsSubs)))\n",
    "pseudoPairN = len(dbicSubs)*len(cbsSubs) - realPairN\n",
    "totalPairN = realPairN + pseudoPairN\n",
    "\n",
    "#define some rolling window parameters based on inputs above\n",
    "numSteps = int(math.ceil((totTRs - winTRs + 1) / stepSize)) #total number of steps based on winTR and stepSize\n",
    "lastTr = winTRs + (numSteps - 1) * stepSize #last TR this approach will analyze\n",
    "TRsLeftOut = totTRs - lastTr #number of TRs that will be left out by the current approach\n",
    "if TRsLeftOut > 0: #if any TRs will end up getting left out based on window and step sizes...\n",
    "    print('The last ' + str(TRsLeftOut) + ' TRs will be left out due to the window and step size!')\n",
    "    \n",
    "#preallocate timing log\n",
    "timeLog_header = ['dbic','cbs','duration']\n",
    "timeLog = np.empty([totalPairN,len(timeLog_header)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def naiveColumnCorr(a, b): \n",
    "    \"\"\"\n",
    "    Naive, slow, \"baseline\" function correlating corresponding columns of two matrices.\n",
    "    Uses a for loop across columns.\n",
    "    \"\"\"\n",
    "    c = np.zeros((a.shape[1]))\n",
    "    for i in range(a.shape[1]):\n",
    "        c[i] = np.corrcoef(a[:, i], b[:, i])[0, 1]\n",
    "\n",
    "    return c\n",
    "\n",
    "\n",
    "def fastColumnCorr(a, b):\n",
    "    \"\"\"\n",
    "    Fast function for correlating corresponding columns of two matrices.\n",
    "    Uses numpy.einsum to avoid loops and do computations directly on matrices.\n",
    "    About ~ 10 times faster than the naive approach in 'naiveColumnCorr'.\n",
    "    Inputs are 2D numpy arrays with the same shape, both sized samples X vars.\n",
    "    NOTES:\n",
    "    Could be further optimized using numpy.einsum_path for contraction order before first use,\n",
    "    then simply calling einsum with that order subsequently. However, it only seems to give a\n",
    "    few percents at best.\n",
    "    contr_order = np.einsum_path(\"ij,ij->j\", aa, bb, optimize='optimal')\n",
    "    cov = np.einsum(\"ij,ij->j\", aa, bb, optimize=contr_order[1])\n",
    "    \"\"\"\n",
    "    # extract the means from each var, in both matrices\n",
    "    aa = a - (np.sum(a, 0) / a.shape[0]) # compute a - mean(a)\n",
    "    bb = b - (np.sum(b, 0) / b.shape[0]) # compute b - mean(b)\n",
    "\n",
    "    # multiply and sum across rows, that is, get dot products of column pairs\n",
    "    cov = np.einsum(\"ij,ij->j\", aa, bb)\n",
    "\n",
    "    # for normalization we need the variances, separately for each var\n",
    "    var_a = np.sum(aa ** 2, 0)\n",
    "    var_b = np.sum(bb ** 2, 0)\n",
    "\n",
    "    return cov / np.sqrt(var_a*var_b)\n",
    "\n",
    "def phase_scrambling(data_matrix, fft_axis=0):\n",
    "    \"\"\"\n",
    "    FOR REAL DATA ONLY, NOT COMPLEX!\n",
    "    Phase-scrambling function for matrices. Preserves the original covariance structure.\n",
    "    After FFT, we add a random phase vector to the FFT components of all time series / vars and do inverse FFT,\n",
    "    as described in Prichard and Theiler (1994, Generating surrogate data for time series with several\n",
    "    simultaneously measured variables. Physical review letters, 73(7), 951).\n",
    "    The returned phase-scrambled data has the same power spectrum as the original but is linearly independent\n",
    "    (zero expected correlation). Covariance structure is preserved, meaning that linear dependencies\n",
    "    across time series is the same in the phase-scrambled data as in the original.\n",
    "    Inputs:\n",
    "    data_matrix:        2D numpy array of reals. Time series (Vars) X samples by default,\n",
    "                        set fft_axis if samples X time series.\n",
    "    fft_axis:           Axis along which FFT / iFFT is calculated. Defaults to 0,\n",
    "                        meaning that FFT is calculated across rows (= each column is a separate time series / var)\n",
    "    Outputs:\n",
    "    data_scrambled:     2D numpy array of reals, contains the phase-scrambled data.\n",
    "                        Same size and dimensions as input \"data_matrix\".\n",
    "                        Returns 0 if input checks failed.\n",
    "    TODO:\n",
    "    - look into implementation with FFTW, which is supposedly faster with repetitive usage (our use case)\n",
    "    \"\"\"\n",
    "\n",
    "    # input checks\n",
    "    if not isinstance(data_matrix, np.ndarray) or len(data_matrix.shape) != 2 or np.iscomplex(data_matrix).any():\n",
    "        print('Input arg \"data_matrix\" should be a 2D numpy array of reals!')\n",
    "        return 0\n",
    "    if fft_axis not in [0, 1]:\n",
    "        print('Input arg \"fft_axis\" should be 0 or 1!')\n",
    "        return 0\n",
    "\n",
    "    # if fft_axis != 0, transpose the data\n",
    "    transposeFlag = False\n",
    "    if fft_axis == 1:\n",
    "        data_matrix = np.transpose(data_matrix)\n",
    "        transposeFlag = True\n",
    "\n",
    "    # do forward FFT, use version for reals, treat data as if vars were in columns\n",
    "    data_fft = np.fft.rfft(data_matrix, axis=0)\n",
    "\n",
    "    # convert to polar coordinates (amplitude/magnitude + phase)\n",
    "    data_fft_amp = np.abs(data_fft)\n",
    "    data_fft_angle = np.angle(data_fft)\n",
    "\n",
    "    # get random phase vector  (values between 0 - 2pi) for all FFT components that are not real by definition\n",
    "    #rng = default_rng()  # new recommended method for random values #JD EDIT  # new recommended method for random values\n",
    "    if data_matrix.shape[0] % 2 == 0:  # if even, first and last components are real\n",
    "        rand_phases = np.hstack(([0] ,(np.random.random_sample((data_fft.shape[0]-2)) * 2 * pi), [0]))\n",
    "    else:  # otherwise only the first component is real\n",
    "        rand_phases = np.hstack(([0], (np.random.random_sample((data_fft.shape[0] - 1)) * 2 * pi)))\n",
    "\n",
    "    # add random phases to the angles of FFT components of all time series / vars,\n",
    "    # addition is with broadcasting (newaxis is needed for broadcasting)\n",
    "    data_fft_angle_rand = data_fft_angle + rand_phases[:, np.newaxis]\n",
    "\n",
    "    # transform back from polar to cartesian, using the randomized phases but the original magnitude / amplitude values\n",
    "    data_scrambled_fft = data_fft_amp * np.exp(1j * data_fft_angle_rand)  # returns complex FFT coefficients\n",
    "\n",
    "    # do inverse FFT\n",
    "    data_scrambled = np.fft.irfft(data_scrambled_fft, n=data_matrix.shape[0], axis=0)\n",
    "\n",
    "    # transpose if necessary\n",
    "    if transposeFlag:\n",
    "        data_scrambled = np.transpose(data_scrambled)\n",
    "\n",
    "    return data_scrambled\n",
    "\n",
    "\n",
    "def phase_scrambling_tests(data_matrix, data_scrambled, fft_axis=0, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Tests for the phase_scrambling function:\n",
    "    (1) compare original FFT amplitudes to scrambled data FFT amplitudes\n",
    "    (2) compare original covariance matrix to scrambled data covariance matrix\n",
    "    (3) check if correlations between original and corresponding scrambled time series are around 0\n",
    "    In the third test, we expect the correlation coefficients to show a normal\n",
    "    distribution around 0, with a \"small\" std. To keep things simple, we do not fit\n",
    "    a normal distribution or try a formal statistical test, but plot the histogram\n",
    "    of the values and decide the test on the basis of the mean and median values\n",
    "    (we check if they are \"close\" to zero, meaning < 0.05).\n",
    "    IMPORTANT: For the second check we calculate the covariance matrices, so for really large data\n",
    "    (e.g. tens of thousands of variables) consider the memory requirements of that step\n",
    "    (~ 1.6 GB for 10^3 variables, considering we need two matrices). The function does not have\n",
    "    internal checks for that.\n",
    "    Inputs:\n",
    "    data_matrix:        2D numpy array of reals. Original data set before phase scrambling.\n",
    "                        Time series (Vars) X samples by default, set fft_axis if samples X time series.\n",
    "    data_scrambled:     2D numpy array of reals, phase scrambled version of \"data_matrix\".\n",
    "                        Same size and shape as \"data_matrix\".\n",
    "    fft_axis:           Axis along which FFT / iFFT is calculated. Defaults to 0,\n",
    "                        meaning that FFT is calculated across rows (= each column is a separate time series / var).\n",
    "    epsilon:            Numeric value, threshold for machine accuracy. Tests 1 and 2 are considered \"passed\"\n",
    "                        (that is, output \"test_results\" values set to True), if numeric inaccuracies\n",
    "                        are below the threshold \"epsilon\". Defaults to 1e-10.\n",
    "    Output:\n",
    "    test_results:       List of booleans, 3-element long. Each boolean value corresponds\n",
    "                        to pass (True) / fail (False) on a test.\n",
    "                        The three values correspond to the (1) FFT amplitude test, (2) covariance matrix test,\n",
    "                        and (3) correlations test.\n",
    "                        Returns 0 if input checks failed.\n",
    "    \"\"\"\n",
    "\n",
    "    # input checks\n",
    "    if not isinstance(data_matrix, np.ndarray) or len(data_matrix.shape) != 2 or np.iscomplex(data_matrix).any():\n",
    "        print('Input arg \"data_matrix\" should be a 2D numpy array of reals!')\n",
    "        return 0\n",
    "    if type(data_matrix) != type(data_scrambled) or data_matrix.shape != data_scrambled.shape or np.iscomplex(data_scrambled).any():\n",
    "        print('Input arg \"data_scrambled\" should be a 2D numpy array of reals, with the same shape as \"data_matrix\"!')\n",
    "        return 0\n",
    "    if fft_axis not in [0, 1]:\n",
    "        print('Input arg \"fft_axis\" should be 0 or 1!')\n",
    "        return 0\n",
    "\n",
    "    # if fft_axis != 0, transpose the data\n",
    "    if fft_axis == 1:\n",
    "        data_matrix = np.transpose(data_matrix)\n",
    "        data_scrambled = np.transpose(data_scrambled)\n",
    "\n",
    "    # init output list\n",
    "    test_results = [False, False, False]\n",
    "\n",
    "    # Check FFT component amplitudes / magnitudes. They should be the same, with differences only due to numeric inaccuracies\n",
    "    # do forward FFT, use version for reals, treat data as if vars were in columns\n",
    "    data_fft = np.fft.rfft(data_matrix, axis=0)\n",
    "    data_scrambled_fft = np.fft.rfft(data_scrambled, axis=0)\n",
    "    # compare magnitudes\n",
    "    amp_diffs = np.abs(data_fft)-np.abs(data_scrambled_fft)\n",
    "    print('Maximum difference between FFT component magnitudes: {:.3e}'.format(amp_diffs.max()))\n",
    "    # set relevant output to True if passed the test\n",
    "    if not (amp_diffs>epsilon).any():\n",
    "        test_results[0] = True\n",
    "        print('First test passed, original and scrambled data have matching FFT component amplitudes.')\n",
    "    else:\n",
    "        print('First test failed, found substantial difference\\n' +\n",
    "              'between original and scrambled data FFT component magnitudes.')\n",
    "\n",
    "    # Check the covariance matrices\n",
    "    data_cov = np.cov(data_matrix, rowvar=False)\n",
    "    data_scrambled_cov = np.cov(data_scrambled, rowvar=False)\n",
    "    maxDiff = (data_cov-data_scrambled_cov).flatten().max()  # maximum difference\n",
    "    print('Maximum difference between covariance matrices: {:.3e}'.format(maxDiff))\n",
    "    # set relevant output to True if passed the test\n",
    "    if maxDiff <= epsilon:\n",
    "        test_results[1] = True\n",
    "        print('Second test passed, original and scrambled data have matching covariance structures.')\n",
    "    else:\n",
    "        print('Second test failed, found substantial difference\\n' +\n",
    "              'between original and scrambled data covariance structures.')\n",
    "\n",
    "    # Check the correlations across original and scrambled vars\n",
    "    ccoeffs = fastColumnCorr(data_matrix, data_scrambled)\n",
    "    # if the mean and median are close to zero (<0.05) we consider that a success\n",
    "    tmp = mplot.hist(ccoeffs, bins=data_matrix.shape[1]//40)\n",
    "    if np.mean(ccoeffs) < 0.05 and np.median(ccoeffs) < 0.05:\n",
    "        test_results[2] = True\n",
    "        print('Third test passed, correlation coefficients group around 0.\\n' +\n",
    "              ' Look at the histogram for further details.')\n",
    "    else:\n",
    "        print('Third test failed, correlation coefficients seem to be biased.\\n' +\n",
    "              'Look at the histogram for further details.')\n",
    "\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ISC functions\n",
    "\n",
    "#OLS - COMPARE WITH sklearn.linear_model.LinearRegression **********************************\n",
    "def reg_m(y, x):\n",
    "    x = np.array(x).T\n",
    "    x = sm.add_constant(x)\n",
    "    results = sm.OLS(endog=y, exog=x).fit()\n",
    "    return results\n",
    "\n",
    "#make 2d X-matrix with variably lagged timeseries [TRs x 2*maxT+1]\n",
    "def make2dVshift(data,maxT):\n",
    "    \n",
    "    \"\"\"\n",
    "    make2dVshift -- make 2d X-matrix with variably lagged timeseries [TRs x 2*maxT+1]\n",
    "    INPUTS:\n",
    "    data = a [TRs x 1] timeseries vector\n",
    "    maxT = absolute value of maximum lag to include in the model [TRs]\n",
    "    OUTPUTS:\n",
    "    vshift = the X-matrix for voxelwise linear models using variably lagged timeseries [TRs x 2*maxT+1]\n",
    "    \"\"\"\n",
    "    vShift = np.empty([len(data), 2*maxT+1]) #preallocate [TRs x shifts]\n",
    "    for i in list(range(-maxT,maxT+1)):\n",
    "        if i < 0:\n",
    "            vShift[:,i+maxT] = np.hstack((data[list(range(-i,data.shape[0]))],np.zeros(-i)))\n",
    "        elif i == 0:\n",
    "            vShift[:,i+maxT] = data\n",
    "        else:\n",
    "            vShift[:,i+maxT] = np.hstack((np.zeros(i), data[list(range(0,data.shape[0]-i))]))\n",
    "    \n",
    "    return vShift\n",
    "\n",
    "#make 3d X-matrix with variably lagged timeseries [TRs x voxels x 2*maxT+1]\n",
    "def make3dVshift(data,maxT):\n",
    "    \n",
    "    \"\"\"\n",
    "    make3dVshift -- make 3d X-matrix with variably lagged timeseries\n",
    "    INPUTS:\n",
    "    data = a [TRs x voxels] timeseries matrix\n",
    "    maxT = absolute value of maximum lag to include in the model [TRs]\n",
    "    OUTPUTS:\n",
    "    vshift = horizontally stacked X-matrices for voxelwise linear models using variably lagged timeseries [TRs x voxels x 2*maxT+1]\n",
    "    \"\"\"\n",
    "    #initialize real time-lagged dataset [TRs x voxels x 2*maxT+1]\n",
    "    vShift = np.empty([data.shape[0],data.shape[1],2*maxT+1])\n",
    "\n",
    "    #if it's the first iteration, then get the real time lagged dataset\n",
    "    for i in list(range(-maxT,maxT+1)): #for each lag\n",
    "\n",
    "        if i < 0: #if no lag\n",
    "            vShift[:,:,i+maxT] = np.vstack((data[list(range(-i,data.shape[0])),:], np.zeros((-i,data.shape[1]))))\n",
    "        elif i == 0:\n",
    "            vShift[:,:,i+maxT] = data\n",
    "        else:\n",
    "            vShift[:,:,i+maxT] = np.vstack((np.zeros((i,data.shape[1])), data[list(range(0,data.shape[0]-i)),:]))\n",
    "    \n",
    "    return vShift\n",
    "\n",
    "def voxWrapper(vShift3D,listener,VOX):\n",
    "    \"\"\"\n",
    "    INPUTS\n",
    "    vShift3D: ___\n",
    "    listener: listener time series\n",
    "    VOX: voxel index\n",
    "\n",
    "    OUTPUTS\n",
    "    b: beta\n",
    "    Rsq: R^2\n",
    "    F: F-test\n",
    "    pF: F-test p-value \n",
    "    \"\"\"\n",
    "    #get voxel-specific X-matrix from the non-scrambled data in 2D\n",
    "    X = np.reshape(vShift3D[:,VOX,:],(vShift3D.shape[0],vShift3D.shape[2]))\n",
    "\n",
    "    #solve linear model vShift*b=y where y is the vector from listener's data\n",
    "    model = reg_m(listener[:,VOX].T, X.T)\n",
    "    \n",
    "    b = model.params[list(range(1,len(model.params)))]\n",
    "    Rsq = model.rsquared\n",
    "    F = model.fvalue\n",
    "    pF = model.f_pvalue\n",
    "\n",
    "    return b, Rsq, F, pF\n",
    "\n",
    "def voxWrapperPerm(vShift3D_scr,listener,Rperm,VOX):\n",
    "    \"\"\"\n",
    "    INPUTS\n",
    "    vShift3D_scr: scrambled ___\n",
    "    listener: listener time series\n",
    "    Rperm: preallocated array for permutation test R^2 values [permutations x voxels]\n",
    "    VOX: voxel index\n",
    "\n",
    "    OUTPUT\n",
    "    pP_Rsq: p-value from [1 x voxels]\n",
    "    \"\"\"\n",
    "    #get voxel-specific X-matrix from the scrambled data in 2D\n",
    "    X = np.reshape(vShift3D_scr[:,VOX,:],(vShift3D_scr.shape[0],vShift3D_scr.shape[2]))\n",
    "\n",
    "    #solve linear model vShift*b=y where y is the vector from listener's data\n",
    "    model = reg_m(listener[:,VOX].T, X.T)\n",
    "\n",
    "    return model.rsquared\n",
    "    \n",
    "#ISC computation\n",
    "def couplingFMRI(speaker, listener, maxT, fitPermuts, method):\n",
    "\n",
    "    #no. of voxels and TRs\n",
    "    voxelN = speaker.shape[1]\n",
    "    trN = speaker.shape[0]\n",
    "\n",
    "    #preallocate results matrices\n",
    "    b = np.empty([2*maxT+1, voxelN])\n",
    "    Rsq = np.empty([voxelN]);\n",
    "    F = np.empty([voxelN]);\n",
    "    pF = np.empty([voxelN]);\n",
    "    pP_F = np.empty([voxelN]);\n",
    "\n",
    "    #print('Data dimensions: ' + str(trN) + ' X ' + str(voxelN));\n",
    "    print('Modeling listener data using lagged time series from speaker...');\n",
    "\n",
    "    if method == 0: #original method\n",
    "\n",
    "        #For each voxel...\n",
    "        for VOX in list(range(0,voxelN)):\n",
    "\n",
    "            #get X matrix of time-shifted speaker timeseries\n",
    "            vShift = make2dVshift(speaker[:,VOX],maxT)\n",
    "\n",
    "            #solve linear model vShift*b=y where y is the vector from listener's data\n",
    "            model = reg_m(listener[:,VOX].T, vShift.T)\n",
    "            b[:,VOX] = model.params[list(range(1,len(model.params)))]\n",
    "            Rsq[VOX] = model.rsquared\n",
    "            F[VOX] = model.fvalue\n",
    "            pF[VOX] = model.f_pvalue\n",
    "\n",
    "            #occassional feedback\n",
    "            if ((VOX + 1) % 10000 == 0) | (voxelN < 10000 & VOX == voxelN-1):\n",
    "                print('\\nFinished with voxel no. ' + str(VOX + 1))\n",
    "\n",
    "            #run permutation test if selected\n",
    "            if fitPermuts > 0:\n",
    "\n",
    "                #preallocate\n",
    "                pP_Rsq = np.empty([voxelN]);\n",
    "                \n",
    "                for PERM in list(range(0,fitPermuts)):\n",
    "                    \n",
    "                    #make time-lagged X-matrices without scrambling the speaker timeseries\n",
    "                    vShift2D = make2dVshift(speaker[:,VOX],maxT)\n",
    "                    \n",
    "                    #scramble the time series\n",
    "                    X = phase_scrambling(vShift2D)\n",
    "                    X = np.vstack((vShift_scr,vShift_scr[0,])) #JD HACK because row nums not preserved\n",
    "\n",
    "                    #solve linear model vShift*b=y where y is the vector from listener's data\n",
    "                    model = reg_m(listener[:,VOX].T, X.T)\n",
    "                    Rperm[PERM,VOX] = model.rsquared\n",
    "                    \n",
    "                    #get permutation test R^2 p-value\n",
    "                    if PERM == firPermuts - 1: #if we're on the last permutation...\n",
    "                        pP_Rsq[VOX] = len(Rperm[:,VOX][Rperm[:,VOX] > Rsq[VOX]]) / float(fitPermuts)\n",
    "\n",
    "            else:\n",
    "                pP_Rsq[VOX] = None\n",
    "\n",
    "    else: #new method\n",
    "        \n",
    "        #preallocate array for Rsq from permutation test\n",
    "        pP_Rsq = np.empty([voxelN]);\n",
    "\n",
    "        if fitPermuts > 0:\n",
    "            \n",
    "            Rperm = np.empty([fitPermuts,voxelN])\n",
    "\n",
    "            for PERM in list(range(0,fitPermuts)):\n",
    "\n",
    "                #if it's the first permutation, set up the non-scrambled time series\n",
    "                if PERM == 0:\n",
    "\n",
    "                    #make time-lagged X-matrices without scrambling the speaker timeseries\n",
    "                    vShift3D = make3dVshift(speaker,maxT)\n",
    "\n",
    "                #scramble the time series\n",
    "                speaker_scr = phase_scrambling(speaker)\n",
    "\n",
    "                #make time-lagged X-matrices\n",
    "                vShift3D_scr = make3dVshift(speaker_scr,maxT)\n",
    "\n",
    "                #if using joblib for voxelwise computations...\n",
    "                if voxParallel == 1:\n",
    "                    \n",
    "                    #non-scrambled\n",
    "                    if PERM == 0:\n",
    "                        \n",
    "                        #run ISC for each voxel using joblib\n",
    "                        tmp = Parallel(n_jobs=numJobs)(delayed(voxWrapper)(vShift3D,listener,VOX) for VOX in range(voxelN))\n",
    "                        \n",
    "                        #reformat\n",
    "                        for VOX in range(voxelN):\n",
    "                            b[:,VOX] = tmp[VOX][0]\n",
    "                            Rsq[VOX] = tmp[VOX][1]\n",
    "                            F[VOX] = tmp[VOX][2]\n",
    "                            pF[VOX] = tmp[VOX][3]\n",
    "                        \n",
    "                    #scrambled\n",
    "                    pP_Rsq_tmp = Parallel(n_jobs=numJobs)(delayed(voxWrapperPerm)(vShift3D_scr,listener,VOX) for VOX in range(voxelN))\n",
    "                    Rperm[PERM,:] = pP_Rsq_tmp\n",
    "                    \n",
    "                    #get p-value from permutated Rsq and F values\n",
    "                    if PERM == fitPermuts-1: #if it's the last permutation...\n",
    "                        pP_Rsq = Parallel(n_jobs=numJobs)(delayed(len(Rperm[:,VOX][Rperm[:,VOX] > Rsq[VOX]]) / float(fitPermuts))(Rperm,fitPermuts,VOX) for VOX in range(voxelN))\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    #for each voxel...\n",
    "                    for VOX in list(range(0,voxelN)):\n",
    "\n",
    "                        #if it's the first permutation... fit the voxelwise models to the non-scrambled data\n",
    "                        if PERM == 0:\n",
    "\n",
    "                            #get voxel-specific X-matrix from the non-scrambled data in 2D\n",
    "                            X = np.reshape(vShift3D[:,VOX,:],(vShift3D.shape[0],vShift3D.shape[2]))\n",
    "\n",
    "                            #solve linear model vShift*b=y where y is the vector from listener's data\n",
    "                            model = reg_m(listener[:,VOX].T, X.T)\n",
    "                            b[:,VOX] = model.params[list(range(1,len(model.params)))]\n",
    "                            Rsq[VOX] = model.rsquared\n",
    "                            F[VOX] = model.fvalue\n",
    "                            pF[VOX] = model.f_pvalue\n",
    "\n",
    "                        #get voxel-specific X-matrix from the scrambled data in 2D\n",
    "                        X = np.reshape(vShift3D_scr[:,VOX,:],(vShift3D_scr.shape[0],vShift3D_scr.shape[2]))\n",
    "\n",
    "                        #solve linear model vShift*b=y where y is the vector from listener's data\n",
    "                        model = reg_m(listener[:,VOX].T, X.T)\n",
    "                        Rperm[PERM,VOX] = model.rsquared\n",
    "\n",
    "                        #get permutation test p-values\n",
    "                        if PERM == fitPermuts-1: #if it's the last permutation...\n",
    "                            pP_Rsq[VOX] = len(Rperm[:,VOX][Rperm[:,VOX] > Rsq[VOX]]) / float(fitPermuts)\n",
    "                        \n",
    "        else: \n",
    "            \n",
    "            #make time-lagged X-matrices without scrambling the speaker timeseries\n",
    "            vShift3D = make3dVshift(speaker,maxT)\n",
    "            \n",
    "            #if using joblib for voxelwise computations...\n",
    "            if voxParallel == 1:\n",
    "                \n",
    "                #run ISC for each voxel using joblib\n",
    "                tmp = Parallel(n_jobs=numJobs)(delayed(voxWrapper)(vShift3D,listener,VOX) for VOX in range(voxelN))\n",
    "                \n",
    "                #reformat\n",
    "                for VOX in range(voxelN):\n",
    "                    b[:,VOX] = tmp[VOX][0]\n",
    "                    Rsq[VOX] = tmp[VOX][1]\n",
    "                    F[VOX] = tmp[VOX][2]\n",
    "                    pF[VOX] = tmp[VOX][3]\n",
    "                    pP_Rsq[VOX] = None\n",
    "                \n",
    "            else: \n",
    "                \n",
    "                #for each voxel...\n",
    "                for VOX in list(range(0,voxelN)):\n",
    "\n",
    "                    #get voxel-specific X-matrix from the non-scrambled data in 2D\n",
    "                    X = np.reshape(vShift3D[:,VOX,:],(vShift3D.shape[0],vShift3D.shape[2]))\n",
    "\n",
    "                    #solve linear model vShift*b=y where y is the vector from listener's data\n",
    "                    model = reg_m(listener[:,VOX].T, X.T)\n",
    "                    b[:,VOX] = model.params[list(range(1,len(model.params)))]\n",
    "                    Rsq[VOX] = model.rsquared\n",
    "                    F[VOX] = model.fvalue\n",
    "                    pF[VOX] = model.f_pvalue\n",
    "                    pP_Rsq[VOX] = None\n",
    "\n",
    "    return b, Rsq, F, pF, pP_Rsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dbicNum</th>\n",
       "      <th>dbicID</th>\n",
       "      <th>cbsNum</th>\n",
       "      <th>cbsID</th>\n",
       "      <th>pairType</th>\n",
       "      <th>condition</th>\n",
       "      <th>dbicSpeaker</th>\n",
       "      <th>sFile</th>\n",
       "      <th>lFile</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dbicNum     dbicID cbsNum      cbsID pairType condition dbicSpeaker  \\\n",
       "0        2  sid000007      2  hid000002        1         0           0   \n",
       "1        2  sid000007      2  hid000002        1         0           1   \n",
       "2        2  sid000007      2  hid000002        1         1           0   \n",
       "3        2  sid000007      2  hid000002        1         1           1   \n",
       "4        2  sid000007      3  hid000003        0         0           0   \n",
       "5        2  sid000007      3  hid000003        0         0           1   \n",
       "6        2  sid000007      3  hid000003        0         1           0   \n",
       "7        2  sid000007      3  hid000003        0         1           1   \n",
       "8        3  sid000009      2  hid000002        0         0           0   \n",
       "9        3  sid000009      2  hid000002        0         0           1   \n",
       "10       3  sid000009      2  hid000002        0         1           0   \n",
       "11       3  sid000009      2  hid000002        0         1           1   \n",
       "12       3  sid000009      3  hid000003        1         0           0   \n",
       "13       3  sid000009      3  hid000003        1         0           1   \n",
       "14       3  sid000009      3  hid000003        1         1           0   \n",
       "15       3  sid000009      3  hid000003        1         1           1   \n",
       "\n",
       "                                                sFile  \\\n",
       "0   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "1   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "2   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "3   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "4   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "5   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "6   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "7   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "8   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "9   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "10  /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "11  /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "12  /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "13  /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "14  /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "15  /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "\n",
       "                                                lFile duration  \n",
       "0   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...      NaN  \n",
       "1   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...      NaN  \n",
       "2   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...      NaN  \n",
       "3   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...      NaN  \n",
       "4   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...      NaN  \n",
       "5   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...      NaN  \n",
       "6   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...      NaN  \n",
       "7   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...      NaN  \n",
       "8   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...      NaN  \n",
       "9   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...      NaN  \n",
       "10  /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...      NaN  \n",
       "11  /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...      NaN  \n",
       "12  /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...      NaN  \n",
       "13  /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...      NaN  \n",
       "14  /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...      NaN  \n",
       "15  /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...      NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make pairMap data frame as a reference for pair information\n",
    "\n",
    "#set column names\n",
    "pairMap_header = ['dbicNum', #DBIC subject number\n",
    "                  'dbicID', #DBIC subject ID (e.g., sid000007)\n",
    "                  'cbsNum', #CBS subject number\n",
    "                  'cbsID', #CBS subject ID\n",
    "                  'pairType', #1=real, 0=pseudo\n",
    "                  'condition', #1=joint, 0=independent\n",
    "                  'dbicSpeaker', #1=DBIC speaker, CBS listener, 0=CBS speaker, DBIC listener\n",
    "                  'sFile', #speaker file name\n",
    "                  'lFile', #listener file name\n",
    "                  'duration'] #ISC duration [min]\n",
    "\n",
    "#number of rows to preallocate for real fit arrays\n",
    "numRows = (realPairN + pseudoPairN) * 4; \n",
    "\n",
    "#preallocate pair map data frame\n",
    "pairMap = pd.DataFrame(columns = pairMap_header, index=range(numRows))\n",
    "\n",
    "#set order in which to load tasks for DBIC and CBS subs within each pair\n",
    "dTask = ['listener','speaker','listener','speaker']\n",
    "cTask = ['speaker','listener','speaker','listener']\n",
    "\n",
    "#initialize pairMap row counter\n",
    "ROW = 0\n",
    "\n",
    "#for each DBIC subject...\n",
    "for dbicPairN in dbicSubs: \n",
    "    \n",
    "    #get DBIC sub ID and run info\n",
    "    dbicSub = pairsAndRuns['DBIC'][dbicPairN] #e.g., 'sid000007'\n",
    "    dbicRunInd = pairsAndRuns['ind_run'][dbicPairN] #current subject's independent run #s\n",
    "    dbicRunJoint = pairsAndRuns['joint_run'][dbicPairN] #current subject's joint run #s\n",
    "    dRun = [dbicRunInd, dbicRunInd, dbicRunJoint, dbicRunJoint] #make an array of independent and joint run #s to simplify loading below\n",
    "     \n",
    "    #get dbic file names\n",
    "    dbicFiles = [[]]*4\n",
    "    for FILE in range(4):\n",
    "        if local == 1: #if loading loading local files...\n",
    "            dbicFiles[FILE] = '/Users/jeffreyknotts/Documents/MATLAB/Wheatley/isc_test/sub-' + dbicSub + \\\n",
    "            '_ses-pair0' + str(dbicPairN + 1) + '_task-storytelling' + str(dRun[FILE]) + '_run-0' + \\\n",
    "            str(dRun[FILE]) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_' + dTask[FILE] + '.mat'  #[TRs x voxels]\n",
    "        else: #if loading loading files from drzeuss...\n",
    "            dbicFiles[FILE] = '/flash/wheatley/adamb/hyperscanning_DBIC_ses2/sub-' + dbicSub + \\\n",
    "            '_fmriprep/fmriprep/sub-' + dbicSub + '/ses-pair0' + str(dbicPairN + 1) + '/func/' + \\\n",
    "            'sub-' + dbicSub + '_ses-pair0' + str(dbicPairN + 1) + '_task-storytelling' + str(dRun[FILE]) + '_run-0' + \\\n",
    "            str(dRun[FILE]) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_' + dTask[FILE] + '.mat'  #[TRs x voxels]\n",
    "    \n",
    "    #for each CBS subject...\n",
    "    for cbsPairN in cbsSubs: \n",
    "        \n",
    "        #get CBS sub ID and run info\n",
    "        cbsSub = pairsAndRuns['CBS'][cbsPairN] #e.g., 'hid000002'\n",
    "        cbsRunInd = pairsAndRuns['ind_run'][cbsPairN]\n",
    "        cbsRunJoint = pairsAndRuns['joint_run'][cbsPairN]\n",
    "        cRun = [cbsRunInd, cbsRunInd, cbsRunJoint, cbsRunJoint] #make an array of independent and joint run #s to simplify loading below\n",
    "        \n",
    "        for FILE in range(4):\n",
    "            \n",
    "            #get dbic file names\n",
    "            cbsFiles = [[]]*4\n",
    "            if local == 1: #if loading loading files from drzeuss...\n",
    "                cbsFiles[FILE] = '/Users/jeffreyknotts/Documents/MATLAB/Wheatley/isc_test/sub-' + cbsSub + \\\n",
    "                '_ses-pair0' + str(cbsPairN + 1) + '_task-storytelling' + str(cRun[FILE]) + '_run-0' + \\\n",
    "                str(cRun[FILE]) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_' + cTask[FILE] + '.mat'  #[TRs x voxels]\n",
    "            else: \n",
    "                cbsFiles[FILE] = '/flash/wheatley/adamb/hyperscanning_CBS/sub-' + cbsSub + \\\n",
    "                '_fmriprep/fmriprep/sub-' + cbsSub + '/ses-pair0' + str(cbsPairN + 1) + '/func/' + \\\n",
    "                'sub-' + cbsSub + '_ses-pair0' + str(cbsPairN + 1) + '_task-storytelling' + str(cRun[FILE]) + '_run-0' + \\\n",
    "                str(cRun[FILE]) + '_bold_space-MNI152NLin2009cAsym_preproc_nuisRegr_' + cTask[FILE] + '.mat'  #[TRs x voxels]\n",
    "            \n",
    "            ##############################\n",
    "            ### index stuff to pairMap ###\n",
    "            ##############################\n",
    "            \n",
    "            #subject numbers and IDs\n",
    "            pairMap['dbicNum'][ROW] = dbicPairN + 1\n",
    "            pairMap['dbicID'][ROW] = dbicSub\n",
    "            pairMap['cbsNum'][ROW] = cbsPairN + 1\n",
    "            pairMap['cbsID'][ROW] = cbsSub\n",
    "            \n",
    "            #pair type\n",
    "            if pairMap['dbicNum'][ROW] == pairMap['cbsNum'][ROW]:\n",
    "                pairMap['pairType'][ROW] = 1 #real pair\n",
    "            else:\n",
    "                pairMap['pairType'][ROW] = 0 #pseudo pair\n",
    "            \n",
    "            #speaker/listener\n",
    "            if ROW % 2: #if it's an odd row - DBIC speaker, CBS listener\n",
    "                pairMap['dbicSpeaker'][ROW] = 1\n",
    "                pairMap['sFile'][ROW] = dbicFiles[FILE] #speaker file name\n",
    "                pairMap['lFile'][ROW] = cbsFiles[FILE] #listener file name\n",
    "            else: #if it's an even row - CBS speaker, DBIC listener\n",
    "                pairMap['dbicSpeaker'][ROW] = 0\n",
    "                pairMap['sFile'][ROW] = cbsFiles[FILE] #speaker file name\n",
    "                pairMap['lFile'][ROW] = dbicFiles[FILE] #listener file name\n",
    "            \n",
    "            #independent/joint condition\n",
    "            if FILE < 2:\n",
    "                pairMap['condition'][ROW] = 0 #independent\n",
    "            else: \n",
    "                pairMap['condition'][ROW] = 1 #joint\n",
    "            \n",
    "            ROW += 1\n",
    "    \n",
    "pairMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   1 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=8)]: Done   2 out of  16 | elapsed:   26.4s remaining:  3.1min\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  16 | elapsed:   26.5s remaining:  1.9min\n",
      "[Parallel(n_jobs=8)]: Done   4 out of  16 | elapsed:   26.5s remaining:  1.3min\n",
      "[Parallel(n_jobs=8)]: Done   5 out of  16 | elapsed:   27.0s remaining:   59.4s\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  16 | elapsed:   27.0s remaining:   45.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  16 | elapsed:   27.1s remaining:   34.8s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of  16 | elapsed:   27.5s remaining:   27.5s\n",
      "[Parallel(n_jobs=8)]: Done   9 out of  16 | elapsed:   48.0s remaining:   37.3s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  16 | elapsed:   48.0s remaining:   28.8s\n",
      "[Parallel(n_jobs=8)]: Done  11 out of  16 | elapsed:   48.2s remaining:   21.9s\n",
      "[Parallel(n_jobs=8)]: Done  12 out of  16 | elapsed:   48.3s remaining:   16.1s\n",
      "[Parallel(n_jobs=8)]: Done  13 out of  16 | elapsed:   49.3s remaining:   11.4s\n",
      "[Parallel(n_jobs=8)]: Done  14 out of  16 | elapsed:   49.5s remaining:    7.1s\n",
      "[Parallel(n_jobs=8)]: Done  16 out of  16 | elapsed:   50.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  16 out of  16 | elapsed:   50.3s finished\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "### ISC ###\n",
    "###########\n",
    "\n",
    "'''\n",
    "Note: removed print updates around couplingISC because joblib renders them kind of meaningless.\n",
    "But using the verbose option in joblib provides helpful progress outputs.\n",
    "'''\n",
    "\n",
    "def ISCwrapper(sFile, lFile, winArray, voxelCoords, pairMap, ROW):\n",
    "            \n",
    "    #get time of start of current ISC\n",
    "    iscStart = time.time() #get starting time\n",
    "    \n",
    "    #get time variables\n",
    "    winTRs = winArray[0] #window size [TRs]\n",
    "    stepSize = winArray[1] #step size [TRs]\n",
    "    numSteps = winArray[2] #number of steps to cover the time series given winTRs and stepSize\n",
    "    \n",
    "    #preallocate results matrices\n",
    "    b = np.empty([2*maxT+1, len(voxelCoords), numSteps])\n",
    "    Rsq = np.empty([numSteps, len(voxelCoords)]);\n",
    "    F = np.empty([numSteps, len(voxelCoords)]);\n",
    "    pF = np.empty([numSteps, len(voxelCoords)]);\n",
    "    pP_Rsq = np.empty([numSteps, len(voxelCoords)]);\n",
    "    \n",
    "    #preallocate step duration array\n",
    "    stepDur = np.empty([numSteps]);\n",
    "    stepDur[:] = np.NaN\n",
    "\n",
    "    #load speaker timeseries\n",
    "    if os.path.isfile(sFile): #if there is a file to load...\n",
    "        dummyFile = sio.loadmat(sFile) #load file\n",
    "        if pairMap['dbicSpeaker'][ROW] == 1:\n",
    "            speaker = dummyFile['dbicSpeaker'][:,voxelCoords] #get timeseries data \n",
    "        else: \n",
    "            speaker = dummyFile['cbsSpeaker'][:,voxelCoords] #get timeseries data    \n",
    "        del dummyFile\n",
    "    else: \n",
    "        print(ROW + ' shit')\n",
    "\n",
    "    #load listener timeseries\n",
    "    if os.path.isfile(lFile):\n",
    "        dummy = sio.loadmat(lFile) #load data\n",
    "        if pairMap['dbicSpeaker'][ROW] == 1:\n",
    "            listener = dummy['cbsListener'][:,voxelCoords] #get time series data\n",
    "        else: \n",
    "            listener = dummy['dbicListener'][:,voxelCoords] #get time series data\n",
    "        del dummy\n",
    "\n",
    "    #Loop over rolling windows...\n",
    "    for STEP in range(numSteps): #for each window...\n",
    "        \n",
    "        #get TRs to use in current window\n",
    "        TRs = list(range(stepSize * STEP,stepSize * STEP + winTRs)); #make sure to start at ZERO here\n",
    "\n",
    "        #run couplingFMRI\n",
    "        b[:,:,STEP], Rsq[STEP,:], F[STEP,:], pF[STEP,:], pP_Rsq[STEP,:]  = couplingFMRI(speaker[TRs,:], listener[TRs,:], maxT, fitPermuts, method)\n",
    "        \n",
    "    #get approximate time to run couplingFMRI for current pair [min]\n",
    "    duration = round((time.time() - iscStart) / 60,2)\n",
    "    \n",
    "    #estimate time remaining and get it in string form\n",
    "    rowsRemaining = pairMap.shape[0] - ROW #number of ISCs left to perform\n",
    "    estTimeRemain = rowsRemaining * duration #estimated time remaining\n",
    "    hrs = math.floor(estTimeRemain / 60)\n",
    "    minFloat = estTimeRemain % 60\n",
    "    mins = math.floor(minFloat)\n",
    "    secs = round((minFloat - mins)*60)\n",
    "    if hrs > 0:\n",
    "        timeString = str(hrs) + ' hr ' + str(mins) + ' min ' + str(secs) + ' s' \n",
    "    else:\n",
    "        timeString = str(mins) + ' min ' + str(secs) + ' s'\n",
    "\n",
    "    #display another update\n",
    "    print('\\n#################################################')\n",
    "    print('### ISC finished! Estimated time remaining: ' + timeString + ' ###')\n",
    "    print('#################################################')\n",
    "    \n",
    "    return b, Rsq, F, pF, pP_Rsq, duration\n",
    "\n",
    "#for each row in pairMap...\n",
    "winArray = [winTRs,stepSize,numSteps]\n",
    "modFits = Parallel(n_jobs=numJobs, verbose=50)(delayed(ISCwrapper)\n",
    "                                              (pairMap['sFile'][ROW],\n",
    "                                               pairMap['lFile'][ROW], \n",
    "                                               winArray, \n",
    "                                               voxelCoords, \n",
    "                                               pairMap, \n",
    "                                               ROW)\n",
    "                                              for ROW in range(pairMap.shape[0]))\n",
    "\n",
    "#add duration to pairMaps\n",
    "for ROW in range(pairMap.shape[0]):\n",
    "    pairMap['duration'][ROW] = modFits[ROW][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dbicNum</th>\n",
       "      <th>dbicID</th>\n",
       "      <th>cbsNum</th>\n",
       "      <th>cbsID</th>\n",
       "      <th>pairType</th>\n",
       "      <th>condition</th>\n",
       "      <th>dbicSpeaker</th>\n",
       "      <th>sFile</th>\n",
       "      <th>lFile</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>sid000007</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>2</td>\n",
       "      <td>hid000002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>sid000009</td>\n",
       "      <td>3</td>\n",
       "      <td>hid000003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_DBIC_ses2/...</td>\n",
       "      <td>/flash/wheatley/adamb/hyperscanning_CBS/sub-hi...</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dbicNum     dbicID cbsNum      cbsID pairType condition dbicSpeaker  \\\n",
       "0        2  sid000007      2  hid000002        1         0           0   \n",
       "1        2  sid000007      2  hid000002        1         0           1   \n",
       "2        2  sid000007      2  hid000002        1         1           0   \n",
       "3        2  sid000007      2  hid000002        1         1           1   \n",
       "4        2  sid000007      3  hid000003        0         0           0   \n",
       "5        2  sid000007      3  hid000003        0         0           1   \n",
       "6        2  sid000007      3  hid000003        0         1           0   \n",
       "7        2  sid000007      3  hid000003        0         1           1   \n",
       "8        3  sid000009      2  hid000002        0         0           0   \n",
       "9        3  sid000009      2  hid000002        0         0           1   \n",
       "10       3  sid000009      2  hid000002        0         1           0   \n",
       "11       3  sid000009      2  hid000002        0         1           1   \n",
       "12       3  sid000009      3  hid000003        1         0           0   \n",
       "13       3  sid000009      3  hid000003        1         0           1   \n",
       "14       3  sid000009      3  hid000003        1         1           0   \n",
       "15       3  sid000009      3  hid000003        1         1           1   \n",
       "\n",
       "                                                sFile  \\\n",
       "0   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "1   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "2   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "3   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "4   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "5   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "6   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "7   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "8   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "9   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "10  /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "11  /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "12  /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "13  /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "14  /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...   \n",
       "15  /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...   \n",
       "\n",
       "                                                lFile duration  \n",
       "0   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...     0.38  \n",
       "1   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...     0.36  \n",
       "2   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...     0.37  \n",
       "3   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...     0.36  \n",
       "4   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...     0.36  \n",
       "5   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...     0.37  \n",
       "6   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...     0.37  \n",
       "7   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...     0.36  \n",
       "8   /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...     0.36  \n",
       "9   /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...     0.36  \n",
       "10  /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...     0.36  \n",
       "11  /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...     0.38  \n",
       "12  /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...     0.37  \n",
       "13  /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...     0.35  \n",
       "14  /flash/wheatley/adamb/hyperscanning_DBIC_ses2/...     0.37  \n",
       "15  /flash/wheatley/adamb/hyperscanning_CBS/sub-hi...     0.38  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014294000731574165"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get total duration\n",
    "endTime = time.time()\n",
    "totalDur = (endTime - startTime) / 3600 #total duration [hrs]\n",
    "totalDur"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
